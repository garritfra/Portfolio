<!DOCTYPE html><html><head><meta name="viewport" content="width=device-width, initial-scale=1"/><meta charSet="utf-8"/><title>Docker in plain english | Garrit&#x27;s Notes</title><meta name="Description" content="Generalist developer writing about fullstack development, system administration and free software."/><link rel="icon" type="image/svg+xml" href="/favicon.svg"/><link rel="webmention" href="https://webmention.io/garrit.xyz/webmention"/><link rel="pingback" href="https://webmention.io/garrit.xyz/xmlrpc"/><link href="https://cdn.jsdelivr.net/npm/shareon@2/dist/shareon.min.css" rel="stylesheet"/><meta name="next-head-count" content="8"/><link rel="preload" href="/_next/static/css/75e7918d9b50f980.css" as="style" crossorigin=""/><link rel="stylesheet" href="/_next/static/css/75e7918d9b50f980.css" crossorigin="" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" crossorigin="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-fa99431b15635937.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/framework-0c7baedefba6b077.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/main-75623049b75f64cc.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/pages/_app-187294a91bbe014b.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/996-5107ae5c71151305.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/939-76783eaa73b07fc4.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/pages/posts/%5Bpost%5D-501d3fa6f1ebe70f.js" defer="" crossorigin=""></script><script src="/_next/static/d_M2mGKYWeh4BkNR6yIoW/_buildManifest.js" defer="" crossorigin=""></script><script src="/_next/static/d_M2mGKYWeh4BkNR6yIoW/_ssgManifest.js" defer="" crossorigin=""></script></head><body><div id="__next"><section class="layout"><header class="header"><nav class="nav" role="navigation" aria-label="main navigation"><div class="header__container"><a href="/" class="header__container__logo underlined">Garrit&#x27;s Notes</a></div><ul class="header__links"><li><a href="/posts" class="underlined">Blog</a></li><li><a href="/contact" class="underlined">Contact</a></li><li><a href="/cv" class="underlined">Resume</a></li></ul></nav></header><div class="content"><article class="page h-entry"><div class="page__info"><h1 class="p-name">Docker in plain english</h1><time class="page__info__date">May 02 2022</time></div><div class="page__body e-content"><p>Recently I saw some fellow Mastodon-users discussing resources and guides to get
into the docker ecosystem. Given that most of my private infrastructure is built
upon docker and docker-compose, I thought I&#x27;d share how <strong>I</strong> use this tool. I
will try to assume no prior container-knowledge, but if anything isn&#x27;t clear to
you, feel free to <a href="/contact">contact me</a>.</p>
<h2 id="docker-101">Docker 101</h2>
<p>First up: What on earth is Docker, and why should I use it?</p>
<p>Docker is a <em>container runtime</em>. It can be used to isolate system resources in a
reproducible manner, meaning if I containerize an application on my machine, I
can be sure that it will function exactly the same on all machines. The benefits
of this are obvious: You more or less eliminate all dependencies to a specific
environment, like the operating system and other software. As long as it&#x27;s the
same CPU-architecture, this sentence holds true: If it runs docker, it can run
your application.</p>
<p>Things running in a container also can&#x27;t break out of this &quot;sandbox&quot;. A process
in a container is only aware of the resources around it, not on the host
machine. Each container is kind of like an operating system <strong>inside</strong> your
actual operating system.</p>
<p>To describe what a container should look like, we need to write a &quot;recipe&quot; for
it. In it, you describe a starting point from which you want to build upon, and
the necessary steps to achieve the desired state. This &quot;recipe&quot; is called a
<code>Dockerfile</code>. A very simple Dockerfile might look like this:</p>
<pre><code>FROM ubuntu

RUN apt update &amp;&amp; apt upgrade -y

CMD [&quot;echo&quot;, &quot;Hello World!&quot;]
</code></pre>
<p>If you now run <code>docker build -t hello-world .</code>, docker will take this recipe and
build an <strong>image</strong> called &quot;hello-world&quot;. This image is a template that describes
the state of your application. In our case, we take the definition provided by
the &quot;ubuntu&quot; image and simply do a system update. Whenever you spawn a container
from this image, it will always start from exactly this state. Note that the
commands in the Dockerfile do not run every time you launch a container! An
image is the <strong>result</strong> of running the commands. The final instruction, <code>CMD</code>,
is the command to run whenever you spawn a container, but more on that later.</p>
<p>Congrats! You just built your very first docker image. To verify that it&#x27;s
actually there, try running <code>docker image ls</code>. This will list all images on your
system:</p>
<pre><code>➜  garrit.xyz git:(master) ✗ docker image ls
REPOSITORY               TAG             IMAGE ID       CREATED          SIZE
hello-world              latest          6e2240011a89   8 minutes ago    109MB
</code></pre>
<p>An image doesn&#x27;t really do anything on its own. You need to tell docker to
construct a container out of that image. A container is essentially an
<strong>instance</strong> of that image. Try running this command:</p>
<pre><code>docker run hello-world
</code></pre>
<p>And, as instructed with the <code>CMD</code> line, you should see the words &quot;Hello World!&quot;
printed on the screen. You can verify that it&#x27;s still there by running <code>docker ps -a</code>, which will list all containers on your system, including the one you
just ran:</p>
<pre><code>CONTAINER ID   IMAGE                    COMMAND                  CREATED          STATUS                      PORTS                                            NAMES
05415bf66a91   hello-world              &quot;bash&quot;                   3 seconds ago    Exited (0) 2 seconds ago
</code></pre>
<p>&quot;This isn&#x27;t really helpful!&quot;, I hear you yell. You&#x27;re right, so let&#x27;s look at a
real world example.</p>
<h2 id="example:-a-simple-node.js-application">Example: A simple Node.js application</h2>
<p>A real world use case for a docker container is run your home-built application.
Say we have a basic Node.js app that we wanted to containerize:</p>
<pre><code>.
├── app.js
├── package-lock.json
└── package.json
</code></pre>
<p>And your main setup-workflow for this application looks something like this:</p>
<pre><code>npm install
npm start
</code></pre>
<p>Remember that a Dockerfile is a <strong>recipe</strong> of how an application is built. A
corresponding recipe could look like this:</p>
<pre><code class="language-Dockerfile"># Declare base image
FROM node:16

# Copy the application into the container
COPY . .

# Install dependencies
RUN npm install

# Launch the application
CMD [&quot;npm&quot;, &quot;start&quot;]
</code></pre>
<p>Like above, you can build this Dockerfile using <code>docker build -t testapp .</code>, or
any name you&#x27;d like to use.</p>
<blockquote>
<p><strong>Quick Tip</strong>: You might also want to add a <code>.Dockerignore</code> file, which lists
files and directories which should not be copied inside the container, just like
a <code>.gitignore</code> file. I usually add <code>node_modules</code> since it will be recreated
when building the image, and some files that are not relevant at runtime, like a
README.</p>
</blockquote>
<p>Running <code>docker image ls</code> should now show the image you just created:</p>
<pre><code>REPOSITORY               TAG             IMAGE ID       CREATED             SIZE
testapp                  latest          463e68d86eee   5 minutes ago       857MB
</code></pre>
<p>You can now &quot;run&quot; the image, which will result in a spawned container. Since
Containers run in their own environment, they won&#x27;t be able to receive any
keystrokes by default, so you can&#x27;t stop the application. To fix this, you can
use the <code>-it</code> flags, which will establish an interactive session to the process
inside the container. This makes it easier to stop the container after it is
created:</p>
<pre><code>docker run -it testapp
</code></pre>
<p>And voila! You should see the output of your application in the terminal. If
you&#x27;ve done some Node.js, this output might be familiar:</p>
<pre><code>➜  testapp git:(master) ✗ docker run -ti testapp

&gt; testapp@1.0.0 start
&gt; node app.js

Example app listening at http://:::8080
</code></pre>
<p>You&#x27;ll soon discover that you can&#x27;t access port 8080 on your machine. Docker has
a powerful networking engine, and each container has its own IP. You <em>could</em>
figure out the IP of your container and access it like that. A simpler approach
though is to just bind a port of your host machine to the container. For
example, let&#x27;s bind our port 4000 to port 8081 of the container. This can be
done using the <code>-p</code> flag of the cli:</p>
<pre><code>docker run -p 4000:8081 -it testapp
</code></pre>
<blockquote>
<p><strong>Quick Tip</strong>: To remember the order of the container- and the host-port, I
always think of the container as laying on my desk. First, I grab the cable (the
host machine) and then plug it into the container. Weird analogy, I know. But it
really helped me make sense of this!</p>
</blockquote>
<p>If you now access <code>http://localhost:4000</code> on your host machine, you should see
your application!</p>
<h2 id="docker-compose-101">Docker Compose 101</h2>
<p>Now that we&#x27;ve looked at the basics of Docker, let&#x27;s talk about Docker Compose.
Docker Compose is a tool that allows you to define and manage multi-container
applications. This means you can use a single docker-compose.yml file to define
the services and dependencies of your application, and then use Docker Compose
to start and stop all of the containers at once.</p>
<p>Using Docker Compose can save you a lot of time and hassle, especially if you
have a complex application with multiple components that need to work together.
With Docker Compose, you can specify the dependencies between your containers,
as well as the ports, volumes, and other settings that they need to run
properly. This makes it much easier to manage and maintain your application, and
allows you to make changes to your environment quickly and easily.</p>
<p>Here is an example docker-compose.yml file for a simple Node.js application:</p>
<pre><code class="language-yaml">version: &#x27;3&#x27;
services:
  app:
    build: .
    ports:
      - 3000:3000
    volumes:
      - .:/usr/src/app
    command: npm start
</code></pre>
<p>In this file, we define a single service called &quot;app&quot; that uses the Dockerfile
in the current directory to build an image. We then map port 3000 on the host
machine to port 3000 on the container, mount the current directory as a volume,
and specify the command to run when the container is started.</p>
<p>To start the containers defined in this docker-compose.yml file, you can run the following command:</p>
<pre><code>docker-compose up
</code></pre>
<p>This will build the images, create the containers, and start all of the
services. You can then access your application at <a href="http://localhost:3000">http://localhost:3000</a>.</p>
<p>To stop the containers and remove them, you can run the following command:</p>
<pre><code>docker-compose down
</code></pre>
<p>This will stop and remove the containers, as well as the networks and volumes
that we&#x27;ve created.</p>
<h2 id="how-i-deploy-my-services">How I deploy my services</h2>
<ul>
<li>Walkthrough of a simple deployment (miniflux?)</li>
<li>Traefik</li>
<li>Local volumes</li>
<li>Permissions</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<ul>
<li>Image size optimizations</li>
</ul>
<p>This is post 030 of <a href="https://100daystooffload.com/">#100DaysToOffload</a>.</p><hr/><p><a href="mailto:garrit@slashdev.space?subject=Re: Docker%20in%20plain%20english">Reply via E-Mail</a></p><a href="https://www.buymeacoffee.com/garrit" target="_blank"><img src="https://img.buymeacoffee.com/button-api/?text=Buy me a coffee&amp;emoji=&amp;slug=garrit&amp;button_colour=FFDD00&amp;font_colour=000000&amp;font_family=Cookie&amp;outline_colour=000000&amp;coffee_colour=ffffff"/></a><p class="page__tag-list"><svg class="page__tag-icon" xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"></path><line x1="7" y1="7" x2="7" y2="7"></line></svg><a href="/posts?tags=guide">#<!-- -->guide</a><a href="/posts?tags=docker">#<!-- -->docker</a><a href="/posts?tags=infrastructure">#<!-- -->infrastructure</a><a href="/posts?tags=100DaysToOffload">#<!-- -->100DaysToOffload</a></p><div class="shareon"><a class="facebook"></a><a class="linkedin"></a><a class="mastodon"></a><a class="pocket"></a><a class="reddit"></a><a class="telegram"></a><a class="twitter"></a><a class="whatsapp"></a></div><hr/><h2>Continue Reading</h2><div><div class="blog__list__post"><time class="blog__list__post__date">Oct 13 2023</time><br/><a href="/posts/2023-10-13-organizing-multiple-git-identities">Organizing multiple Git identities</a></div><div class="blog__list__post"><time class="blog__list__post__date">Jun 01 2023</time><br/><a href="/posts/2023-06-01-single-page-applications-on-github-pages">Single Page Applications on GitHub Pages</a></div><div class="blog__list__post"><time class="blog__list__post__date">Apr 28 2023</time><br/><a href="/posts/2023-04-28-serverless-framework-retrospective">Serverless Framework Retrospective</a></div><div class="blog__list__post"><time class="blog__list__post__date">Apr 27 2023</time><br/><a href="/posts/2023-04-27-migrating-homeassistant-from-sd-to-ssd">Migrating Homeassistant from SD to SSD</a></div><div class="blog__list__post"><time class="blog__list__post__date">Apr 12 2023</time><br/><a href="/posts/2023-04-12-instant-dark-theme">Instant dark theme</a></div></div></div></article></div><footer class="footer"><div class="footer__content"><h3>Links of Interest</h3><a href="/rss.xml">RSS Feed</a><br/><a href="/todo">Todo List</a><br/><a href="https://keyoxide.org/hkp/garrit@slashdev.space">PGP Key</a><br/><a href="/guestbook">Guestbook</a><br/><a href="/blogroll">Blogroll</a><br/><a href="/ctf">Capture the Flag</a><h3>Elsewhere</h3><a href="https://github.com/garritfra" rel="me">Github</a><br/><a href="https://www.linkedin.com/in/garritfranke/">LinkedIn</a><br/><a href="https://fosstodon.org/@garritfra">Mastodon (ActivityPub)</a><br/><a href="/contact">Contact</a></div><p>👻 Proud member of <a target="_blank" href="https://darktheme.club/">darktheme.club</a> <!-- -->👻</p><p>© 2018-<!-- -->2023<!-- --> Garrit Franke<br/><a href="/privacy">Privacy</a> |<!-- --> <a target="_blank" href="https://github.com/garritfra/garrit.xyz">Source Code</a></p></footer></section></div><script id="__NEXT_DATA__" type="application/json" crossorigin="">{"props":{"pageProps":{"post":{"slug":"_2022-05-02-docker-in-plain-english","markdownBody":"\nRecently I saw some fellow Mastodon-users discussing resources and guides to get\ninto the docker ecosystem. Given that most of my private infrastructure is built\nupon docker and docker-compose, I thought I'd share how **I** use this tool. I\nwill try to assume no prior container-knowledge, but if anything isn't clear to\nyou, feel free to [contact me](/contact).\n\n## Docker 101\n\nFirst up: What on earth is Docker, and why should I use it?\n\nDocker is a _container runtime_. It can be used to isolate system resources in a\nreproducible manner, meaning if I containerize an application on my machine, I\ncan be sure that it will function exactly the same on all machines. The benefits\nof this are obvious: You more or less eliminate all dependencies to a specific\nenvironment, like the operating system and other software. As long as it's the\nsame CPU-architecture, this sentence holds true: If it runs docker, it can run\nyour application.\n\nThings running in a container also can't break out of this \"sandbox\". A process\nin a container is only aware of the resources around it, not on the host\nmachine. Each container is kind of like an operating system **inside** your\nactual operating system.\n\nTo describe what a container should look like, we need to write a \"recipe\" for\nit. In it, you describe a starting point from which you want to build upon, and\nthe necessary steps to achieve the desired state. This \"recipe\" is called a\n`Dockerfile`. A very simple Dockerfile might look like this:\n\n```\nFROM ubuntu\n\nRUN apt update \u0026\u0026 apt upgrade -y\n\nCMD [\"echo\", \"Hello World!\"]\n```\n\nIf you now run `docker build -t hello-world .`, docker will take this recipe and\nbuild an **image** called \"hello-world\". This image is a template that describes\nthe state of your application. In our case, we take the definition provided by\nthe \"ubuntu\" image and simply do a system update. Whenever you spawn a container\nfrom this image, it will always start from exactly this state. Note that the\ncommands in the Dockerfile do not run every time you launch a container! An\nimage is the **result** of running the commands. The final instruction, `CMD`,\nis the command to run whenever you spawn a container, but more on that later.\n\nCongrats! You just built your very first docker image. To verify that it's\nactually there, try running `docker image ls`. This will list all images on your\nsystem:\n\n```\n➜  garrit.xyz git:(master) ✗ docker image ls\nREPOSITORY               TAG             IMAGE ID       CREATED          SIZE\nhello-world              latest          6e2240011a89   8 minutes ago    109MB\n```\n\nAn image doesn't really do anything on its own. You need to tell docker to\nconstruct a container out of that image. A container is essentially an\n**instance** of that image. Try running this command:\n\n```\ndocker run hello-world\n```\n\nAnd, as instructed with the `CMD` line, you should see the words \"Hello World!\"\nprinted on the screen. You can verify that it's still there by running `docker ps -a`, which will list all containers on your system, including the one you\njust ran:\n\n```\nCONTAINER ID   IMAGE                    COMMAND                  CREATED          STATUS                      PORTS                                            NAMES\n05415bf66a91   hello-world              \"bash\"                   3 seconds ago    Exited (0) 2 seconds ago\n```\n\n\"This isn't really helpful!\", I hear you yell. You're right, so let's look at a\nreal world example.\n\n## Example: A simple Node.js application\n\nA real world use case for a docker container is run your home-built application.\nSay we have a basic Node.js app that we wanted to containerize:\n\n```\n.\n├── app.js\n├── package-lock.json\n└── package.json\n```\n\nAnd your main setup-workflow for this application looks something like this:\n\n```\nnpm install\nnpm start\n```\n\nRemember that a Dockerfile is a **recipe** of how an application is built. A\ncorresponding recipe could look like this:\n\n```Dockerfile\n# Declare base image\nFROM node:16\n\n# Copy the application into the container\nCOPY . .\n\n# Install dependencies\nRUN npm install\n\n# Launch the application\nCMD [\"npm\", \"start\"]\n```\n\nLike above, you can build this Dockerfile using `docker build -t testapp .`, or\nany name you'd like to use.\n\n\u003e **Quick Tip**: You might also want to add a `.Dockerignore` file, which lists\n\u003e files and directories which should not be copied inside the container, just like\n\u003e a `.gitignore` file. I usually add `node_modules` since it will be recreated\n\u003e when building the image, and some files that are not relevant at runtime, like a\n\u003e README.\n\nRunning `docker image ls` should now show the image you just created:\n\n```\nREPOSITORY               TAG             IMAGE ID       CREATED             SIZE\ntestapp                  latest          463e68d86eee   5 minutes ago       857MB\n```\n\nYou can now \"run\" the image, which will result in a spawned container. Since\nContainers run in their own environment, they won't be able to receive any\nkeystrokes by default, so you can't stop the application. To fix this, you can\nuse the `-it` flags, which will establish an interactive session to the process\ninside the container. This makes it easier to stop the container after it is\ncreated:\n\n```\ndocker run -it testapp\n```\n\nAnd voila! You should see the output of your application in the terminal. If\nyou've done some Node.js, this output might be familiar:\n\n```\n➜  testapp git:(master) ✗ docker run -ti testapp\n\n\u003e testapp@1.0.0 start\n\u003e node app.js\n\nExample app listening at http://:::8080\n```\n\nYou'll soon discover that you can't access port 8080 on your machine. Docker has\na powerful networking engine, and each container has its own IP. You _could_\nfigure out the IP of your container and access it like that. A simpler approach\nthough is to just bind a port of your host machine to the container. For\nexample, let's bind our port 4000 to port 8081 of the container. This can be\ndone using the `-p` flag of the cli:\n\n```\ndocker run -p 4000:8081 -it testapp\n```\n\n\u003e **Quick Tip**: To remember the order of the container- and the host-port, I\n\u003e always think of the container as laying on my desk. First, I grab the cable (the\n\u003e host machine) and then plug it into the container. Weird analogy, I know. But it\n\u003e really helped me make sense of this!\n\nIf you now access `http://localhost:4000` on your host machine, you should see\nyour application!\n\n## Docker Compose 101\n\nNow that we've looked at the basics of Docker, let's talk about Docker Compose.\nDocker Compose is a tool that allows you to define and manage multi-container\napplications. This means you can use a single docker-compose.yml file to define\nthe services and dependencies of your application, and then use Docker Compose\nto start and stop all of the containers at once.\n\nUsing Docker Compose can save you a lot of time and hassle, especially if you\nhave a complex application with multiple components that need to work together.\nWith Docker Compose, you can specify the dependencies between your containers,\nas well as the ports, volumes, and other settings that they need to run\nproperly. This makes it much easier to manage and maintain your application, and\nallows you to make changes to your environment quickly and easily.\n\nHere is an example docker-compose.yml file for a simple Node.js application:\n\n```yaml\nversion: '3'\nservices:\n  app:\n    build: .\n    ports:\n      - 3000:3000\n    volumes:\n      - .:/usr/src/app\n    command: npm start\n```\n\nIn this file, we define a single service called \"app\" that uses the Dockerfile\nin the current directory to build an image. We then map port 3000 on the host\nmachine to port 3000 on the container, mount the current directory as a volume,\nand specify the command to run when the container is started.\n\nTo start the containers defined in this docker-compose.yml file, you can run the following command:\n\n```\ndocker-compose up\n```\n\nThis will build the images, create the containers, and start all of the\nservices. You can then access your application at http://localhost:3000.\n\nTo stop the containers and remove them, you can run the following command:\n\n```\ndocker-compose down\n```\n\nThis will stop and remove the containers, as well as the networks and volumes\nthat we've created.\n\n## How I deploy my services\n\n- Walkthrough of a simple deployment (miniflux?)\n- Traefik\n- Local volumes\n- Permissions\n\n## Conclusion\n\n- Image size optimizations\n\nThis is post 030 of [#100DaysToOffload](https://100daystooffload.com/).\n","frontmatter":{"title":"Docker in plain english","date":"2022-05-02","tags":"guide, docker, infrastructure, 100DaysToOffload"},"tags":["guide","docker","infrastructure","100DaysToOffload"]},"recommendedPosts":[{"slug":"2023-10-13-organizing-multiple-git-identities","frontmatter":{"title":"Organizing multiple Git identities","date":"2023-10-13","tags":"100DaysToOffload, guide, note, til, git, tech"},"tags":["100DaysToOffload","guide","note","til","git","tech"]},{"slug":"2023-06-01-single-page-applications-on-github-pages","frontmatter":{"title":"Single Page Applications on GitHub Pages","date":"2023-06-01","tags":"100DaysToOffload, guide, note, web, javascript, github"},"tags":["100DaysToOffload","guide","note","web","javascript","github"]},{"slug":"2023-04-28-serverless-framework-retrospective","frontmatter":{"title":"Serverless Framework Retrospective","date":"2023-04-28","tags":"100DaysToOffload, infrastructure, aws, note, terraform, learnings, devops, serverless"},"tags":["100DaysToOffload","infrastructure","aws","note","terraform","learnings","devops","serverless"]},{"slug":"2023-04-27-migrating-homeassistant-from-sd-to-ssd","frontmatter":{"title":"Migrating Homeassistant from SD to SSD","date":"2023-04-27","tags":"100DaysToOffload, guide, note, homeassistant, homelab"},"tags":["100DaysToOffload","guide","note","homeassistant","homelab"]},{"slug":"2023-04-12-instant-dark-theme","frontmatter":{"title":"Instant dark theme","date":"2023-04-12","tags":"100DaysToOffload, guide, note, learnings, web, css, til"},"tags":["100DaysToOffload","guide","note","learnings","web","css","til"]}]},"__N_SSG":true},"page":"/posts/[post]","query":{"post":"_2022-05-02-docker-in-plain-english"},"buildId":"d_M2mGKYWeh4BkNR6yIoW","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>