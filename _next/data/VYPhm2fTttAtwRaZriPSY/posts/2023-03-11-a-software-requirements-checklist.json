{"pageProps":{"post":{"slug":"2023-03-11-a-software-requirements-checklist","markdownBody":"\r\nI just found a [great post](https://www.etsy.com/codeascraft/a-checklist-manifetsy) on the Etsy Engineering blog suggesting a possible checklist for new product requirements. In reality, this checklist is very hard to fulfill, but it's a nice reminder of what a well thought out requirement could look like.\r\n\r\n### Scope\r\n\r\n- Is the feature meant to be very polished and finished or are we just trying to get user feedback as an MVP?\r\n- If we are running a MVP, is the current feature a true MVP? How can we simplify or cut scope?\r\n\r\n### Eligibility\r\n\r\n- What populations should be included or excluded from the experiment? When should users see this feature? (Which pages, signed in/signed out, mobile, desktop, etc.)\r\nWhere/when should bucketing occur?\r\n- Will the experiment conflict with any other experiments? Do the experiments need to run exclusively?\r\n- What countries should the experiment run in (can impact translations)?\r\n\r\n### A11Y\r\n\r\n- Is there any special accessibility work this feature will require? If extra work is anticipated, check in early with our a11y team.\r\n- When testing and developing we should keep two users in mind - a keyboard user and a voice over user, do we need to add other code for these users?\r\n\r\n### Translations\r\n\r\n- Are there any strings to be translated that should be submitted ASAP?\r\n- Do we need to translate any labels for a11y?\r\n\r\n### Observability\r\n\r\n- How will we know that the feature is working? Are there existing graphs we can use or do we need new ones?\r\n- Should any of these metrics have a threshold or alerting?\r\n- Are we missing any key events to obtain user feedback?\r\n- How will we compare our control and variant?\r\n\r\n### Performance\r\n\r\n- Is there anything in my experiment that could degrade performance of the site?\r\n- Do I need an operational experiment to verify that Iâ€™m not impacting performance?\r\n\r\n### Error States\r\n\r\n- Do we have designs for loading states?\r\n- Do we have designs for unsuccessful requests and error handling?\r\n- Do we have informative logging when there are errors?\r\n\r\n### QA\r\n\r\n- What set of browsers and devices should we test our new feature against?\r\n- Which user perspectives do we need to test?\r\n\r\n### Ramping\r\n\r\n- What will our ramping strategy be?\r\n\r\n---\r\n\r\nCheck out the [original post](https://www.etsy.com/codeascraft/a-checklist-manifetsy) for a full writeup and the intentions behind this checklist.\r\n\r\n---\r\n\r\nThis is post 056 of [#100DaysToOffload](https://100daystooffload.com/).\r\n","frontmatter":{"title":"A software requirements checklist","date":"2023-03-11","tags":"100DaysToOffload, note, quote, practices"},"tags":["100DaysToOffload","note","quote","practices"]},"recommendedPosts":[{"slug":"2023-05-19-work-batch-sizing","markdownBody":"\nI've been playing \n[Carcassonne](https://en.m.wikipedia.org/wiki/Carcassonne_(board_game)) a lot with my girlfriend recently. It's a boardgame about building cities, roads and farms, and each completed \"project\" earns you some amount of points. The twist is that there's only a limited number of tiles, and once all tiles are used, the game is over unfinished projects are discarded.\n\nThe first couple of playthroughs I tried to maximize my score by increasing the number of projects I actively had going. I'd start a new city or road whenever I could, thinking that the multipliers you sometimes get would pay off in the end. Boy was I wrong.\n\nWhere I'm from, we have multiple sayings for this approach. \"Having too many irons in the fire\" or \"dancing on too many parties\". I was too busy starting new projects instead of making actual progress.\n\nA far better approach is to finish projects early, earning less points, but with a greater certainty that they will pay off. With every project you start, the likelyhood of the other projects paying off decreases.\n\nKeeping batch sizes small was a key concept of the [lean manufacturing movement](https://en.m.wikipedia.org/wiki/Lean_manufacturing) in the 1980s, and has since been adopted by the [DevOps movement](https://de.m.wikipedia.org/wiki/DevOps) for the IT industry. If you want to learn more about this topic, you should check out [The DevOps Handbook](https://itrevolution.com/product/the-devops-handbook-second-edition/). It goes well beyond the basics of making IT processes more productive and efficient.\n\nAfter realizing that small batch sizes are the key to success, I haven't lost a game of Carcassonne since. I hope you're not reading this, honey.ðŸ¤­\n\n---\n\nThis is post 068 of [#100DaysToOffload](https://100daystooffload.com/).\n","frontmatter":{"title":"Optimizing work batch size","date":"2023-05-19","tags":"100DaysToOffload, note, practices, learnings, life, devops"},"tags":["100DaysToOffload","note","practices","learnings","life","devops"]},{"slug":"2023-04-22-the-role-of-a-devops-engineer","markdownBody":"\nThe term \"DevOps\" can be interpreted in many different ways. It's often thrown around as a buzzword whenever somebody is talking about \"what comes after development\". Obviously, it's not just that. Or is it? It depends on whom you're talking to.\r\n\r\nAlthough I just recently started my new role as a \"DevOps Engineer\", I'm still discovering what that term means to me. I just had a fruitful conversation with the DevOps lead of a client, and they phrased this role in a very fitting way.\r\n\r\n> A DevOps Engineer doesn't push the button, they enable the developers to push the button themselves.\r\n\r\nTo me this role is fascinating, since it touches so many different aspects of software delivery.\r\n\r\n---\r\n\r\nThis is post 065 of [#100DaysToOffload](https://100daystooffload.com/).\n","frontmatter":{"title":"The role of a DevOps Engineer","date":"2023-04-22","tags":"100DaysToOffload, note, practices, devops"},"tags":["100DaysToOffload","note","practices","devops"]},{"slug":"2023-03-26-software-is-not-defined-by-the-language-it's-written-in","markdownBody":"\nRust is not just a programming language, it's also a status symbol. By now, it kind of became a meme that people writing programs in Rust have to make explicit that \"X is written in Rust\".\n\nHow fast or safe the language is doesn't define how good the software is. Software in TypeScript can be just as good as software written in C, if written by the right people.\n\nWhen starting a new project, try to focus on the domain of the problem and pick a language based on that. Don't decide on the language before you know what problem you're trying to solve. If the answer to this is always one option (like Rust), [you might be in a bubble](https://seths.blog/2023/03/the-answer-to-every-question/).\n\n---\n\nThis is post 060 of [#100DaysToOffload](https://100daystooffload.com/).\n\n\n\n","frontmatter":{"title":"Software is not defined by the language it's written in","date":"2023-03-26","tags":"100DaysToOffload, note, practices, opinion"},"tags":["100DaysToOffload","note","practices","opinion"]},{"slug":"2023-02-14-openssf-best-practices","markdownBody":"\nThe Open Source Security Foundation (OpenSSF) provides [a list of best\npractices](https://bestpractices.coreinfrastructure.org/en/criteria/0) for open\nsource projects. Although this list is tailored towards free and open source\nprojects, I believe that this list is valuable for *all* software projects.\nHere's a breakdown of all practices that I consider generic to all projects, no\nmatter its license, alongside some personal notes.\n\n## Basics\n\n### Basic project website content\n\nThe project website MUST succinctly describe what the software does (what problem does it solve?).\n\n> A website might not always apply, but a README is a good place to put this information.\n\nThe information on how to contribute MUST explain the contribution process (e.g., are pull requests used?)\n\n> This information is also best placed in the README.\n\nThe information on how to contribute SHOULD include the requirements for acceptable contributions (e.g., a reference to any required coding standard)\n\n> -> README.\n\n### Documentation\n\nThe project MUST provide basic documentation for the software produced by the\nproject.\n\nThe project MUST provide reference documentation that describes the external\ninterface (both input and output) of the software produced by the project.\n\n> I wouldn't consider reference documentation a requirement, but it's nice to\nhave.\n\n### Other\n\nThe project sites (website, repository, and download URLs) MUST support HTTPS using TLS.\n\n## Change Control\n\n### Public version-controlled source repository\n\nThe project MUST have a version-controlled source repository ~~that is publicly readable and has a URL~~.\n\nThe project's source repository MUST track what changes were made, who made\nthe changes, and when the changes were made.\n\nTo enable collaborative review, the project's source repository MUST include interim versions for review between releases; it MUST NOT include only final releases.\n\n> In some cases, code can't or shouldn't be versioned. For most website projects,\nreview environments in merge requests (Vercel, Netlify, GitLab) could be\nconsidered.\n\nIt is SUGGESTED that common distributed version control software be used (e.g., git) for the project's source repository.\n\n### Unique version numbering\n\nThe project results MUST have a unique version identifier for each release\nintended to be used by users.\n\n> Commit hashes can be used as unique version numbers in some cases.\n\nIt is SUGGESTED that the Semantic Versioning (SemVer) or Calendar Versioning\n(CalVer) version numbering format be used for releases. It is SUGGESTED that\nthose who use CalVer include a micro level value.\n\n> As mentioned above, projects that are constantly in motion (e.g.\n[darktheme.club](https://darktheme.club/)) might want to consider using commit\nhashes for version numbers instead.\n\nIt is SUGGESTED that projects identify each release within their version\ncontrol system. For example, it is SUGGESTED that those using git identify each\nrelease using git tags.\n\n> Git tags are often neglected during development, but can be very useful.\n\n### Release notes\n\nThe project MUST provide, in each release, release notes that are a\nhuman-readable summary of major changes in that release to help users determine\nif they should upgrade and what the upgrade impact will be. The release notes\nMUST NOT be the raw output of a version control log (e.g., the \"git log\" command\nresults are not release notes). Projects whose results are not intended for\nreuse in multiple locations (such as the software for a single website or\nservice) AND employ continuous delivery MAY select \"N/A\".\n\n> I wrote [a post](/posts/2021-02-20-changelogs) about changelogs a while back.\n\n\nThe release notes MUST identify every publicly known run-time vulnerability\nfixed in this release that already had a CVE assignment or similar when the\nrelease was created. This criterion may be marked as not applicable (N/A) if\nusers typically cannot practically update the software themselves (e.g., as\nis often true for kernel updates). This criterion applies only to the\nproject results, not to its dependencies. If there are no release notes or\nthere have been no publicly known vulnerabilities, choose N/A.\n\n## Reporting\n\n### Vulnerability report process\n\nIf private vulnerability reports are supported, the project MUST include how\nto send the information in a way that is kept private.\n\n> For proprietary projects, it's often a good idea to have a public \"Report an issue\"\nfeature.\n\n## Quality\n\n### Working build system\n\nIf the software produced by the project requires building for use, the\nproject MUST provide a working build system that can automatically rebuild\nthe software from source code.\n\nIt is SUGGESTED that common tools be used for building the software.\n\n### Automated test suite\n\nThe project MUST use at least one automated test suite ~~that is publicly\nreleased as FLOSS (this test suite may be maintained as a separate FLOSS\nproject)~~. The project MUST clearly show or document how to run the test\nsuite(s) (e.g., via a continuous integration (CI) script or via documentation in\nfiles such as BUILD.md, README.md, or CONTRIBUTING.md).\n\nA test suite SHOULD be invocable in a standard way for that language.\n\nE.g. `npm run test`, `cargo test`, etc.\n\nIt is SUGGESTED that the test suite cover most (or ideally all) the code\nbranches, input fields, and functionality.\n\n> Write tests if they are useful, not for the sake of having 100% test coverage.\n\nIt is SUGGESTED that the project implement continuous integration (where new\nor changed code is frequently integrated into a central code repository and\nautomated tests are run on the result).\n\n### New functionality testing\n\nThe project MUST have a general policy (formal or not) that as major new\nfunctionality is added to the software produced by the project, tests of that\nfunctionality should be added to an automated test suite.\n\nThe project MUST have evidence that the test policy for adding tests has been\nadhered to in the most recent major changes to the software produced by the\nproject.\n\n> This is often covered if you have a CI pipeline.\n\nIt is SUGGESTED that this policy on adding tests (see test_policy) be\ndocumented in the instructions for change proposals.\n\n> Consider adding a checkbox to your merge request template. For reference, here's\na checklist that I often use in templates:\n>\n> ```\n> # Checklist:\n>\n> - [ ] documented in the changelog\n> - [ ] sufficiently tested\n> - [ ] sufficiently documented\n> ```\n\n### Warning flags\n\nThe project MUST enable one or more compiler warning flags, a \"safe\"\nlanguage mode, or use a separate \"linter\" tool to look for code quality\nerrors or common simple mistakes, if there is at least one FLOSS tool that\ncan implement this criterion in the selected language.\n\nThe project MUST address warnings.\n\n> Ensure this by disallowing warnings in your CI pipeline.\n\nIt is SUGGESTED that projects be maximally strict with warnings in the\nsoftware produced by the project, where practical.\n\n## Security\n\n### Secure development knowledge\n\nThe project MUST have at least one primary developer who knows how to design\nsecure software.\n\nAt least one of the project's primary developers MUST know of common kinds of\nerrors that lead to vulnerabilities in this kind of software, as well as at\nleast one method to counter or mitigate each of them.\n\n> Easier said than done, but be vocal if you're hesitant towards a feature or\nimplementation path.\n\n### Use basic good cryptographic practices\n\nThe software produced by the project MUST use, by default, only cryptographic\nprotocols and algorithms that are publicly published and reviewed by experts (if\ncryptographic protocols and algorithms are used).\n\nIf the software produced by the project is an application or library, and its\nprimary purpose is not to implement cryptography, then it SHOULD only call on\nsoftware specifically designed to implement cryptographic functions; it SHOULD\nNOT re-implement its own.\n\n> Don't reinvent the wheel. Not just for cryptography.\n\nThe security mechanisms within the software produced by the project MUST use\ndefault keylengths that at least meet the NIST minimum requirements through the\nyear 2030 (as stated in 2012). It MUST be possible to configure the software so\nthat smaller keylengths are completely disabled.\n\nThe default security mechanisms within the software produced by the project\nMUST NOT depend on broken cryptographic algorithms (e.g., MD4, MD5, single DES,\nRC4, Dual_EC_DRBG), or use cipher modes that are inappropriate to the context,\nunless they are necessary to implement an interoperable protocol (where the\nprotocol implemented is the most recent version of that standard broadly\nsupported by the network ecosystem, that ecosystem requires the use of such an\nalgorithm or mode, and that ecosystem does not offer any more secure\nalternative). The documentation MUST describe any relevant security risks and\nany known mitigations if these broken algorithms or modes are necessary for an\ninteroperable protocol.\n\nThe default security mechanisms within the software produced by the project\nSHOULD NOT depend on cryptographic algorithms or modes with known serious\nweaknesses (e.g., the SHA-1 cryptographic hash algorithm or the CBC mode in\nSSH).\n\nThe security mechanisms within the software produced by the project SHOULD\nimplement perfect forward secrecy for key agreement protocols so a session key\nderived from a set of long-term keys cannot be compromised if one of the\nlong-term keys is compromised in the future.\n\nIf the software produced by the project causes the storing of passwords for\nauthentication of external users, the passwords MUST be stored as iterated\nhashes with a per-user salt by using a key stretching (iterated) algorithm\n(e.g., Argon2id, Bcrypt, Scrypt, or PBKDF2). See also OWASP Password Storage\nCheat Sheet).\n\nThe security mechanisms within the software produced by the project MUST\ngenerate all cryptographic keys and nonces using a cryptographically secure\nrandom number generator, and MUST NOT do so using generators that are\ncryptographically insecure.\n\n### Secured delivery against man-in-the-middle (MITM) attacks\n\nThe project MUST use a delivery mechanism that counters MITM attacks. Using\nhttps or ssh+scp is acceptable.\n\nA cryptographic hash (e.g., a sha1sum) MUST NOT be retrieved over http and\nused without checking for a cryptographic signature.\n\n### Publicly known vulnerabilities fixed\n\nThere MUST be no unpatched vulnerabilities of medium or higher severity that\nhave been publicly known for more than 60 days.\n\n> This can be ensured using\n[Dependabot](https://docs.github.com/en/code-security/dependabot/working-with-dependabot)\nor [Renovate](https://docs.renovatebot.com/)\n\nProjects SHOULD fix all critical vulnerabilities rapidly after they are reported.\n\n> Again, use automatic dependency updating mechanisms for this.\n\n### Other security issues\n\nThe public repositories MUST NOT leak a valid private credential (e.g., a\nworking password or private key) that is intended to limit public access.\n\n## Analysis\n\n### Static code analysis\n\nAt least one static code analysis tool (beyond compiler warnings and \"safe\"\nlanguage modes) MUST be applied to any proposed major production release of the\nsoftware before its release, if there is at least one ~~FLOSS~~ tool that implements\nthis criterion in the selected language.\n\nIt is SUGGESTED that at least one of the static analysis tools used for the\nstatic_analysis criterion include rules or approaches to look for common\nvulnerabilities in the analyzed language or environment.\n\nAll medium and higher severity exploitable vulnerabilities discovered with\nstatic code analysis MUST be fixed in a timely way after they are confirmed.\n\nIt is SUGGESTED that static source code analysis occur on every commit or at\nleast daily.\n\n### Dynamic code analysis\n\nIt is SUGGESTED that at least one dynamic analysis tool be applied to any\nproposed major production release of the software before its release.\n\nIt is SUGGESTED that if the software produced by the project includes\nsoftware written using a memory-unsafe language (e.g., C or C++), then at\nleast one dynamic tool (e.g., a fuzzer or web application scanner) be\nroutinely used in combination with a mechanism to detect memory safety\nproblems such as buffer overwrites.\n\n> This is often overlooked.\n\nIt is SUGGESTED that the project use a configuration for at least some dynamic\nanalysis (such as testing or fuzzing) which enables many assertions. In many\ncases these assertions should not be enabled in production builds.\n\nAll medium and higher severity exploitable vulnerabilities discovered with\ndynamic code analysis MUST be fixed in a timely way after they are confirmed.\n\n---\n\nThis is post 046 of [#100DaysToOffload](https://100daystooffload.com/).\n","frontmatter":{"title":"OpenSSF Best Practices","date":"2023-02-14","tags":"note, 100DaysToOffload, practices"},"tags":["note","100DaysToOffload","practices"]},{"slug":"2022-12-05-contributing-to-open-source-knowledge","markdownBody":"\nI wrote the initial draft for this post a few months ago, traveling through\nNorway in a rented campervan. While roaming the beautiful landscapes, I spent a\nlot of time thinking. Reading books while traveling really is the best way to\nfind new inspiration.\n\nOn our trip, we wanted to try out an alternative to Google Maps. Most of the\nOpenStreetMap-based apps lack important features, but we recently stumbled upon\n[MagicEarth](https://www.magicearth.com/), which perfectly fills the void.\nOpenStreetMap has been 95% accurate for us. Those last 5% are mostly less famous\nhiking trails and attractions that could easily be filled in by people like you\nand me. This inspired me to write this blog post, where I share six ways that\nyou can contribute to open source knowledge right now.\n\n## OpenStreetMap\n\nAs mentioned above, I spotted some minor inconsistencies in\n[OpenStreetMap](https://openstreetmap.org) while driving through Norway. We\ntracked our hikes with an app that is able to export a GPX file, which can be\nimported to OpenStreetMap to check if the trail matches (or if it is missing),\nand took note of incorrect or sloppy roads/buildings. Back home, I plan to sit\ndown and fix up those issues.\n\nBut you don't have to be on a roadtrip to contribute to OpenStreetMap! Chances\nare you know your local surroundings pretty well. Just navigate to your\nneighborhood and see what could be improved. Maybe you know a public toilet, a\npark or a secret road that is not shown on the map? As a matter of fact, my\nprivate address was missing, so I added it via the editor. I can now use any of\nthe many OpenStreetMap-based apps to navigate home!\n\n## Wikipedia (and other wikis)\n\nI often feel like I can't contribute much to the vast knowledge of Wikipedia.\n_Other people are way smarter than me_ and whatnot. But while you might not be\nable to publish worthy edits to a well-known topic, you might know some things\nthat others haven't thought of. Is there an entry about your local town? Is\nthere an interesting member of your (past) family that others might want to read\nabout?\n\nOf course, there are other wikis beside Wikipedia. Are you using a little-known\ntool that has open source documentation in the form of a wiki? How can it be\nimproved?\n\n## Observation\n\nYou might have never heard of [observation.org](https://observation.org). It's\nan open biodiversity- and nature-database. I just recently learned about them in\nour local museum. They had a special exhibition about insects, and called out\nfor contributions to map out our local flora and fauna.\n\nThe idea is simple: snap a picture of an interesting looking insect or plant,\nupload it using the website (or one of their apps) and create an \"observation\".\nUsing this information, researchers will be able to understand the biodiversity\nof your area. The information is free to use, and anyone can contribute!\n\n## Wardriving\n\nWardriving is a fun and useful way to contribute to open source knowledge. By\ndriving around with a device that can detect and record wireless networks, you\ncan help to map out the wireless coverage in your area. This information can be\nused by researchers, network operators, and other interested parties to\nunderstand the availability and quality of wireless networks.\n\nOne popular tool for wardriving is [WiGLE](https://wigle.net/). WiGLE allows you\nto easily collect and share information about wireless networks, and contribute\nto the global wireless map. To get started with WiGLE, you will need a device\nthat can detect and record wireless networks. This can be a smartphone, laptop,\nor dedicated wardriving device. You will also need to download and install the\nWiGLE app, and some basic knowledge of how to use it.\n\nOnce you have set up WiGLE, you can start driving around and mapping out the\nwireless networks in your area. As you collect data, it will be automatically\nuploaded to the WiGLE database, where it can be used by researchers and other\ninterested parties. Wardriving with WiGLE is a fun and easy way to help advance\nscientific research and understanding.\n\n## folding@home\n\nAnother way to contribute to open source knowledge is to participate in the\n[folding@home](https://foldingathome.org/) project. folding@home is a\ndistributed computing project that uses the idle processing power of volunteers'\ncomputers to perform scientific calculations and simulations. These calculations\nare used to study a wide range of topics, including protein folding, drug\ndesign, and the origins of the universe.\n\nBy joining the folding@home network, you can help to advance scientific research\nand discovery. The project is open to anyone, and you can participate using your\npersonal computer, laptop, or even your smartphone. All you need to do is\ndownload and install the folding@home software, and then select the types of\ncalculations that you want to contribute to.\n\nThe folding@home project is a great way to put your idle computing power to good\nuse, and to contribute to the global effort to advance scientific knowledge. To\nlearn more, visit the [folding@home website](https://foldingathome.org/).\n\n## Blog posts\n\nWriting a blog post is a fun and engaging way to contribute to open source\nknowledge. You don't need to be a professional writer or have a formal writing\nstyle. Just jot down some notes about a topic that you are passionate about, and\nshare your experiences and expertise with others.\n\nNot only will you be helping others to learn from your experiences, but writing\na blog post can also be beneficial for yourself. Capturing your thoughts and\nideas in writing can help you to better understand and organize your own\nknowledge. It can also be a great way to reflect on your experiences and to\nlearn from your successes and failures.\n\nIf you're interested in blogging, you might want to check out the\n[100DaysToOffload](https://100daystooffload.com/) project!\n\n# Wrapping up\n\nAs you can see, there are many ways that you can contribute to open source\nknowledge, even if you don't have a lot of time or expertise. By participating\nin projects like OpenStreetMap, Wikipedia, observation.org, and folding@home, or\nby sharing your experiences and expertise through blog posts, you can make a\nreal difference in the community.\n\nWhy not give it a try? You might be surprised by how much you can learn and how\nmuch you can help others. And who knows, you might even have some fun along the\nway! Thanks for reading, and happy contributing!\n\nThis is post 044 of [#100DaysToOffload](https://100daystooffload.com/).\n","frontmatter":{"title":"6 ways you can contribute to open knowledge right now","date":"2022-12-05","tags":"note, guide, practices, 100DaysToOffload"},"tags":["note","guide","practices","100DaysToOffload"]}]},"__N_SSG":true}