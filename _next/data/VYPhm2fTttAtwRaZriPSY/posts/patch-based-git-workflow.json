{"pageProps":{"post":{"slug":"patch-based-git-workflow","markdownBody":"\nIf you have ever contributed to an open source project, chances are you have opened a pull request on GitHub or a similar platform to present your code to the maintainers. While this is a very approachable way of getting your code reviewed, some projects have decided against using pull requests and instead accept patches via email.\n\n## An introduction to patches\n\nA patch is essentially a git commit expressed in plain text. It describes what commit the change is based on, and what has changed. A basic patch looks like this:\n\n```\nFrom 92132241233033a123c4fa833449d6a0d550219c Mon Sep 17 00:00:00 2001\nFrom: Bob <bob@example.com>\nDate: Tue, 25 May 2009 15:42:16 +0200\nSubject: [PATCH 1/2] first change\n\n---\n test.txt |    1 +-\n 1 files changed, 1 insertions(+), 1 deletions(-)\n\ndiff --git a/test.txt b/test.txt\nindex 7634da4..270eb95 100644\n--- a/test.txt\n+++ b/test.txt\n@@ -1 +1 @@\n-Hallo Bob\n+Hallo Alice!\n```\n\nAs you can see, it is very readable for both the reviewer and the machine.\n\n## Sending and receiving patches\n\nThe easiest way you can generate a patch from a commit is to use `git-format-patch`:\n\n```\ngit format-patch HEAD^\n```\n\nThis will generate a `.patch` file, that can be embedded into an email and sent to the maintainers. Oftentimes they will then reply to your mail with some inline comments about your code.\n\nTo simplify this process further, git has the `send-email` command, which let's you send the patch directly to someone without needing to embed it manually. I won't go into details about this, but there is a [well written guide](https://git-send-email.io/) on how to set it up.\n\nIf you have received a patch from someone, you can apply it to your tree with the `am` (apply mail) command:\n\n```\ngit am < 0001-first-change.patch\n```\n\ncheck your `git log` to see the patch in form of the latest commit.\n\n## Why even bother\n\nYou might think that this is just a silly and outdated approach to collaborative development. \"Why not simply open a pull request?\" you might ask. Some projects, especially low-level oriented ones like the Linux kernel, do not want to rely on third-party platforms like GitHub to host their code, with good reasons:\n\n1. Everyone can participate! You don't need to register an account on some proprietary website to collaborate in a project that uses a patch-based workflow. You don't even have to expose your identity, if you don't want to. All you need is an email-address, and frankly most of us have one.\n2. It's plain simple! Once you get used to generating and applying patches on the command line, it is in fact easier and faster than opening a pull request in some clunky GUI. It doesn't get simpler than plain text.\n3. It is rewarding! Once you have submitted a patch to a project, there is no better feeling than getting a simple \"Applied, thanks!\" response from a maintainer. And if it's a response that contains feedback rather than an approval, it feels even better to submit that reworked code again and get it eventually applied.\n\n## Conclusion\n\nThe patch-based workflow is an alternative way to collaborate with developers. If it helps you in your day to day business depends on the projects you are contributing to, but in the end it is always good to have many tools under your belt.\n","frontmatter":{"title":"The Patch-Based Git Workflow","date":"2020-09-28","tags":"git, guide, programming"},"tags":["git","guide","programming"]},"recommendedPosts":[{"slug":"2023-06-01-single-page-applications-on-github-pages","markdownBody":"\nMy latest project, [sendpasswords.net](https://sendpasswords.net/) is a [Single Page Application](https://developer.mozilla.org/en-US/docs/Glossary/SPA) deployed on GitHub Pages.\n\nGitHub Pages is configured in a way to host static HTML files without any bells and whistles. This means that if you try to fetch a document that's *not* the index, for example `/foo`, the server will try to load the file with that name. \n\nBy nature, SPAs only consist of a single HTML entry point (`index.html` in most cases). It's responsible for routing the user to the correct page if there are multiple paths. And here's the crux: if the user tries to load `/foo`, he will not land at the SPA entry point. Instead, he will see a `404` error.\n\n## The solution\n\nA `404` response will automatically return a file called `404.html`, which we can use to our advantage. After building the application, simply copy the `index.html` to `404.html`, as demonstrated by [this commit](https://github.com/garritfra/sendpasswords.net/commit/66bdb68c229a3ac3386f7816a746155e658eb586). This will use `index.html` to serve the application on the root level, and `404.html` to load *the same app* if the page doesn't exist as a file. Whether the `index.html` is needed if there's already a `404.html` is up to you. I left it in to make clear that this is just a workaround.\n\nThis is a [well known](https://stackoverflow.com/a/69308662/9046809) workaround, but I wanted to bring some extra awareness to it, since it's a problem I ran into a couple of times so far. Happy SPAing!\n\n---\n\nThis is post 069 (nice) of [#100DaysToOffload](https://100daystooffload.com/).\n","frontmatter":{"title":"Single Page Applications on GitHub Pages","date":"2023-06-01","tags":"100DaysToOffload, guide, note, web, javascript, github"},"tags":["100DaysToOffload","guide","note","web","javascript","github"]},{"slug":"2023-04-27-migrating-homeassistant-from-sd-to-ssd","markdownBody":"\nI finally got frustrated with the performance of my Raspberry Pi 4 running Homeassistant on a SD card, so I went ahead and got an SSD.\r\n\r\nThe migration was **very** easy:\r\n\r\n1. Create and download a full backup through the UI\r\n2. Flash Homeassistant onto the SSD\r\n3. Remove the SD card and plug the SSD into a USB 3.0 port of the Pi\r\n4. Boot\r\n5. Go through the onboarding procedure\r\n6. Restore Backup\r\n7. Profit\r\n\r\nIt worked like a charm! The speed has improved A LOT, and everything was set up as it should be. \r\n\r\n...Until we turned on the lights in the livingroom. My ZigBee-dongle, plugged into another USB port, wasn't able to communicate with the devices on the network.\r\n\r\nAfter some digging around, I came across several threads stating that an SSD over USB 3.0 apparently creates a lot of interference to surrounding hardware, including my ZigBee dongle. The fix was simple: either get an extension port for the dongle, or plug the SSD into a USB 2.0 port of the Pi. Since I didn't have an extension cord to get the dongle far away enough from the SSD, I went with the latter option for now. And that fixed it! The performance was much worse, but still better than the SD I used before. My next step will be to grab an extension cord from my parents. I'm sure they won't mind.\r\n\r\nI hope this helps!\r\n\r\n---\r\n\r\nThis is post 066 of [#100DaysToOffload](https://100daystooffload.com/).\r\n\r\n\r\n\r\n\r\n\n","frontmatter":{"title":"Migrating Homeassistant from SD to SSD","date":"2023-04-27","tags":"100DaysToOffload, guide, note, homeassistant, homelab"},"tags":["100DaysToOffload","guide","note","homeassistant","homelab"]},{"slug":"2023-04-12-instant-dark-theme","markdownBody":"\nThanks to [Jacksons](https://jacksonchen666.com/) [update to darktheme.club](https://github.com/garritfra/darktheme.club/pull/79), I just came across a neat little [CSS property](https://developer.mozilla.org/en-US/docs/Web/CSS/color-scheme) that turns a mostly CSS-free document into a pleasantly dark site:\r\n\r\n```css\r\n:root {\r\n  color-scheme: light dark;\r\n}\r\n```\r\n\r\nThis will adjust all elements on the page to the color scheme preferred by the user - without any other custom styles! ðŸ¤¯ It is also [widely supported](https://caniuse.com/mdn-css_properties_color-scheme) by browsers.\r\n\r\nI've always been quite dependent on CSS-frameworks for any project I'm starting. Going forward, I'd be interested to see how framework-less sites would feel using this property. If all else fails, there's always the awesome [simple.css](https://simplecss.org/) library, which you can slap on top of a raw document to make it pretty (and dark, if preferred) without using custom classes.\r\n\r\n---\r\n\r\nThis is post 064 of [#100DaysToOffload](https://100daystooffload.com/).\n","frontmatter":{"title":"Instant dark theme","date":"2023-04-12","tags":"100DaysToOffload, guide, note, learnings, web, css, til"},"tags":["100DaysToOffload","guide","note","learnings","web","css","til"]},{"slug":"2023-03-30-designing-resilient-cloud-infrastructure","markdownBody":"\r\nAs mentioned in a [previous post](/posts/2023-03-16-terraform-project-learnings), I'm currently finishing up building my first cloud infrastructure on AWS for a client at work. During the development, I learned a lot about designing components to be resilient and scalable. Here are some key takeaways.\r\n\r\nOne of the most critical components of a resilient infrastructure is redundancy. On AWS, you place your components inside a \"region\". This could be `eu-central-1` (Frankfurt) or `us-east-1` (North Virgina), etc. To further reduce the risk of an outage, each region is divided into multiple [Availability Zones](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.RegionsAndAvailabilityZones.html) (AZs). The AZs of a region are usually located some distance apart from each other. In case of a flood, a fire or a bomb detonating near one AZ, the other AZs should in most cases still be intact. You should have at least two, preferably three replicas of each component across multiple availability zones in a region. By having replicas of your components in different availability zones, you reduce the risk of downtime caused by an outage in a single availability zone.\r\n\r\nAnother way to ensure scalability and resilience for your database is to use [Aurora Serverless v2](https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-serverless-v2.html). This database service is specifically designed for scalable, on-demand, and cost-effective performance. The database scales itself up or down based on the workload, which allows you to automatically and dynamically adjust the database capacity to meet the demand of your application, ensuring that your application is responsive and performs well without the need for manual intervention. Adding Serverless instances to an existing RDS cluster is also a seemless proccess.\r\n\r\nIn addition to switching to Aurora Serverless v2, using read replicas for cache and database in a separate availability zone can act as a hot standby without extra configuration. Keep in mind that read replicas are only utilized by explicitly using the read-only endpoint of a cluster. But even if you're only using the \"main\" cluster endpoint (and therefore just the primary instance), a read replica can promote itself to the primary instance in case of a fail over, which drastically reduces downtime.\r\n\r\nWhen using Amazon Elastic Container Service (ECS), use Fargate as opposed to EC2 instances. Fargate is a serverless compute engine for containers that allows you to run containers without having to manage the underlying infrastructure. It smartly locates instances across availability zones, ensuring that your application is always available.\r\n\r\nIn conclusion, you should always ensure that there are more than one instance of a component in your infrastructure. There are also services on AWS that abstract away the physical infrastructure (Fargate, S3, Lambda) and use a multi-AZ pattern by default.\r\n\r\n---\r\n\r\nThis is post 061 of [#100DaysToOffload](https://100daystooffload.com/).\r\n\r\n","frontmatter":{"title":"Designing resilient cloud infrastructure","date":"2023-03-30","tags":"100DaysToOffload, infrastructure, aws, guide, note, learnings"},"tags":["100DaysToOffload","infrastructure","aws","guide","note","learnings"]},{"slug":"2023-03-23-fullscreen-terminals-in-vscode","markdownBody":"\nI often find myself using a \"real\" terminal alongside my VSCode setup, because for some tasks the built-in terminal, due to its small size, is quite flimsy to use. *But*! I just found out there's a a way to switch the terminal into fullscreen mode, using the \"View: Toggle Maximized Panel\" command.\r\n\r\nYou can bind it to a shortcut, which makes switching between editor and terminal a breeze! Simply add this to your `keybindings.json` (also accessible via the [command palette](https://code.visualstudio.com/docs/getstarted/userinterface#_command-palette)):\r\n\r\n```\r\n    {\r\n        \"key\": \"cmd+alt+m\",\r\n        \"command\": \"workbench.action.toggleMaximizedPanel\"\r\n    }\r\n```\r\n\r\n### References\r\n\r\n- [Original StackOverflow answer](https://stackoverflow.com/a/48512128/9046809)\r\n\r\n---\r\n\r\nThis is post 059 of [#100DaysToOffload](https://100daystooffload.com/).\r\n\n","frontmatter":{"title":"Fullscreen Terminals in VSCode","date":"2023-03-23","tags":"100DaysToOffload, guide, note, editors"},"tags":["100DaysToOffload","guide","note","editors"]}]},"__N_SSG":true}