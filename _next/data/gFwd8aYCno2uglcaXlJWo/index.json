{"pageProps":{"markdownBody":"# I'm Garrit, a generalist software developer.\n\nMy interests include...\n\n- Fullstack Development\n- System Administration\n- Programming Language Design\n- Minimalist Software\n- Free Software\n\n&emsp;\n\nOn my [blog](/posts), I ramble about software and tech-related topics. Check\nout my [todos](/todo) if you need inspiration for your next project.\n\nI'm always up for a chat. Feel free to [reach out](/contact), or leave a note in\nmy [guestbook](/guestbook)!\n\nPssst! Can you find all [hidden flags](/ctf) on this page?\n\n## Projects\n\n**[seeking-maintainers.net](https://seeking-maintainers.net/)**\n\nAn index of open source projects seeking new maintainers.\n\n**[darktheme.club](https://darktheme.club/)**\n\nThe Darktheme Club is a collection of accessible web pages from across the Internet.\n\n**[qbe-rs](https://github.com/garritfra/qbe-rs)**\n\nA Rust crate that seeks to provide a Rust-y representation of QBE IR. It can be\nused by compilers for code generation.\n\n**[Antimony Programming language](https://github.com/antimony-lang/antimony)**\n\nA bullshit-free programming language that compiles to JavaScript.\n","recentPosts":[{"slug":"2023-03-30-designing-resilient-cloud-infrastructure","markdownBody":"\nAs mentioned in a [previous post](/posts/2023-03-16-terraform-project-learnings), I'm currently finishing up building my first cloud infrastructure for a client at work. During the development, I learned a lot about designing components to be resilient and scalable. Here are some key takeaways.\r\n\r\nOne of the most critical components of a resilient infrastructure is redundancy. On AWS, you place your components inside a \"region\". This could be `eu-central-1` (Frankfurt) or `us-east-1` (North Virgina), etc. To further reduce the risk of an outage, each region is divided into multiple [Availability Zones](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.RegionsAndAvailabilityZones.html) (AZs). The AZs of a region are usually located some distance apart from each other. In case of a flood, a fire or a bomb detonating near one AZ, the other AZs should in most cases still be intact. You should have at least two, preferably three replicas of each component across multiple availability zones in a region. By having replicas of your components in different availability zones, you reduce the risk of downtime caused by an outage in a single availability zone.\r\n\r\nAnother way to ensure scalability and resilience for your database is to use [Aurora Serverless v2](https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-serverless-v2.html). This database service is specifically designed for scalable, on-demand, and cost-effective performance. The database scales itself up or down based on the workload, which allows you to automatically and dynamically adjust the database capacity to meet the demand of your application, ensuring that your application is responsive and performs well without the need for manual intervention. Adding Serverless instances to an existing RDS cluster is also a seemless proccess.\r\n\r\nIn addition to switching to Aurora Serverless v2, using read replicas for cache and database in a separate availability zone can act as a hot standby without extra configuration. Keep in mind that read replicas are only utilized by explicitly using the read-only endpoint of a cluster. But even if you're only using the \"main\" cluster endpoint (and therefore just the primary instance), a read replica can promote itself to the primary instance in case of a fail over, which drastically reduces downtime.\r\n\r\nWhen using Amazon Elastic Container Service (ECS), use Fargate as opposed to EC2 instances. Fargate is a serverless compute engine for containers that allows you to run containers without having to manage the underlying infrastructure. It smartly locates instances across availability zones, ensuring that your application is always available.\r\n\r\nIn conclusion, you should always ensure that there are more than one instance of a component in your infrastructure. There are also services on AWS that abstract away the physical infrastructure (Fargate, S3, Lambda) and use a multi-AZ pattern by default.\r\n\r\n---\r\n\r\nThis is post 061 of [#100DaysToOffload](https://100daystooffload.com/).\r\n\n","frontmatter":{"title":"Designing resilient cloud infrastructure","date":"2023-03-30","tags":"100DaysToOffload, infrastructure, aws, guide, note, learnings"},"tags":["100DaysToOffload","infrastructure","aws","guide","note","learnings"]},{"slug":"2023-03-26-software-is-not-defined-by-the-language-it's-written-in","markdownBody":"\nRust is not just a programming language, it's also a status symbol. By now, it kind of became a meme that people writing programs in Rust have to make explicit that \"X is written in Rust\".\n\nHow fast or safe the language is doesn't define how good the software is. Software in TypeScript can be just as good as software written in C, if written by the right people.\n\nWhen starting a new project, try to focus on the domain of the problem and pick a language based on that. Don't decide on the language before you know what problem you're trying to solve. If the answer to this is always one option (like Rust), [you might be in a bubble](https://seths.blog/2023/03/the-answer-to-every-question/).\n\n---\n\nThis is post 060 of [#100DaysToOffload](https://100daystooffload.com/).\n\n\n\n","frontmatter":{"title":"Software is not defined by the language it's written in","date":"2023-03-26","tags":"100DaysToOffload, note, practices, opinion"},"tags":["100DaysToOffload","note","practices","opinion"]},{"slug":"2023-03-23-fullscreen-terminals-in-vscode","markdownBody":"\nI often find myself using a \"real\" terminal alongside my VSCode setup, because for some tasks the built-in terminal, due to its small size, is quite flimsy to use. *But*! I just found out there's a a way to switch the terminal into fullscreen mode, using the \"View: Toggle Maximized Panel\" command.\r\n\r\nYou can bind it to a shortcut, which makes switching between editor and terminal a breeze! Simply add this to your `keybindings.json` (also accessible via the [command palette](https://code.visualstudio.com/docs/getstarted/userinterface#_command-palette)):\r\n\r\n```\r\n    {\r\n        \"key\": \"cmd+alt+m\",\r\n        \"command\": \"workbench.action.toggleMaximizedPanel\"\r\n    }\r\n```\r\n\r\n### References\r\n\r\n- [Original StackOverflow answer](https://stackoverflow.com/a/48512128/9046809)\r\n\r\n---\r\n\r\nThis is post 059 of [#100DaysToOffload](https://100daystooffload.com/).\r\n\n","frontmatter":{"title":"Fullscreen Terminals in VSCode","date":"2023-03-23","tags":"100DaysToOffload, guide, note, editors"},"tags":["100DaysToOffload","guide","note","editors"]},{"slug":"2023-03-21-i-wont-buy-a-yubikey","markdownBody":"\nI have a YubiKey that I use for work, and I love using it. But I won't get one for my personal life.\n\nI've been thinking about this for some time now, but I ultimately don't think the benefits outweigh the hassle of always carrying around another device that I risk losing or breaking.\n\nA Yubikey provides a very good second factor, but so does my phone. My phone, just like a Yubikey, is locked behind a third factor (a pin or biometric sensor), so my phone essentially *is* a Yubikey. You can argue that the authenticator app on my phone (bitwarden) can be hacked, but I'm willing to take that risk if it means I have to reset all security measures on all accounts if I lose the key.\n\nSo, I'm not getting a Yubikey.\n\n---\n\nThis is post 058 of [#100DaysToOffload](https://100daystooffload.com/).\n\n","frontmatter":{"title":"I won't buy a YubiKey","date":"2023-03-21","tags":"100DaysToOffload, note, opinion, privacy, security"},"tags":["100DaysToOffload","note","opinion","privacy","security"]},{"slug":"2023-03-16-terraform-project-learnings","markdownBody":"\r\nI just finished my first ever infrastructure project for a client. My Terraform skills are good enough to be dangerous, but during the development of this project I learned a lot that I would do differently next time.\r\n\r\n## Project structure\r\n\r\nHaving worked with semi-professional Terraform code before, I applied what I knew to my new project. That was mainly that we have a shared base and an overlay directory for each environment. I went with a single Terraform module for the shared infrastructure, and variables for each environment. Naively, roughly every service had their own file.\r\n\r\n```\r\n.\r\n├── modules\r\n│   └── infrastructure\r\n│       ├── alb.tf\r\n│       ├── cache.tf\r\n│       ├── database.tf\r\n│       ├── dns.tf\r\n│       ├── ecr.tf\r\n│       ├── ecs.tf\r\n│       ├── iam.tf\r\n│       ├── logs.tf\r\n│       ├── main.tf\r\n│       ├── network.tf\r\n│       ├── secrets.tf\r\n│       ├── security.tf\r\n│       ├── ssl.tf\r\n│       ├── state.tf\r\n│       └── variables.tf\r\n├── production\r\n│   ├── main.tf\r\n│   └── secrets.tf\r\n└── staging\r\n    ├── main.tf\r\n    └── secrets.tf\r\n```\r\n\r\nThis works very well, but I already started running into issues extending this setup. For my next project, I would probably find individual components and turn them into smaller reusable submodules. If I were to rewrite the project above, I would probably structure it like this (not a complete project, but I think you get the idea):\r\n\r\n```\r\n.\r\n├── modules\r\n│   └── infrastructure\r\n│       ├── main.tf\r\n│       ├── modules\r\n│       │   ├── database\r\n│       │   │   ├── iam.tf\r\n│       │   │   ├── logs.tf\r\n│       │   │   ├── main.tf\r\n│       │   │   ├── outputs.tf\r\n│       │   │   ├── rds.tf\r\n│       │   │   └── variables.tf\r\n│       │   ├── loadbalancer\r\n│       │   │   ├── alb.tf\r\n│       │   │   ├── logs.tf\r\n│       │   │   ├── main.tf\r\n│       │   │   ├── outputs.tf\r\n│       │   │   └── variables.tf\r\n│       │   ├── network\r\n│       │   │   ├── dns.tf\r\n│       │   │   ├── logs.tf\r\n│       │   │   ├── main.tf\r\n│       │   │   ├── outputs.tf\r\n│       │   │   ├── ssl.tf\r\n│       │   │   ├── variables.tf\r\n│       │   │   └── vpc.tf\r\n│       │   ├── service\r\n│       │   │   ├── ecr.tf\r\n│       │   │   ├── ecs.tf\r\n│       │   │   ├── iam.tf\r\n│       │   │   ├── logs.tf\r\n│       │   │   ├── main.tf\r\n│       │   │   ├── outputs.tf\r\n│       │   │   └── variables.tf\r\n│       │   └── state\r\n│       │       ├── locks.tf\r\n│       │       ├── main.tf\r\n│       │       ├── outputs.tf\r\n│       │       ├── s3.tf\r\n│       │       └── variables.tf\r\n│       ├── main.tf\r\n│       ├── outputs.tf\r\n│       └── variables.tf\r\n├── production\r\n│   ├── main.tf\r\n│   └── secrets.tf\r\n└── staging\r\n    ├── main.tf\r\n    └── secrets.tf\r\n```\r\n\r\n## Secrets\r\n\r\nI decided to use [git-crypt](https://github.com/AGWA/git-crypt) to manage secrets, but that was only before I learned about [SOPS](https://github.com/mozilla/sops). It's too late to migrate now, but if I could, I would choose SOPS for secrets any day of the week for upcoming projects. It even has a [Terraform provider](https://registry.terraform.io/providers/carlpett/sops/latest/docs), so there's no excuse not to use it. ;)\r\n\r\n## Conclusion\r\n\r\nOverall I'm pretty happy with how the project turned out, but there are some things that I learned during this project that will pay off later.\r\n\r\n---\r\n\r\nThis is post 057 of [#100DaysToOffload](https://100daystooffload.com/).\r\n","frontmatter":{"title":"Terraform project learnings","date":"2023-03-16","tags":"100DaysToOffload, infrastructure, aws, note, terraform, learnings"},"tags":["100DaysToOffload","infrastructure","aws","note","terraform","learnings"]}]},"__N_SSG":true}