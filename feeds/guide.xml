<?xml version="1.0"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>
            garrit.xyz
        </title>
        <link>
            https://garrit.xyz
        </link>
        <description>
            Garrit Franke
        </description>
        <language>
            en
        </language>
        <lastBuildDate>
            Mon, 03 Jun 2024 00:00:00 +0000
        </lastBuildDate>
        <item>
            <title>
                I just cleaned up 40 GB of Brew caches
            </title>
            <guid>
                https://garrit.xyz/posts/2024-06-03-i-just-cleaned-up-40-gb-of-brew-caches
            </guid>
            <link>
                https://garrit.xyz/posts/2024-06-03-i-just-cleaned-up-40-gb-of-brew-caches?utm_source=rss
            </link>
            <pubDate>
                Mon, 03 Jun 2024 00:00:00 +0000
            </pubDate>
            <description>
                <![CDATA[<blockquote><p><strong>EDIT</strong>: This trick will probably not be as effective on your system as it was on my system. After writing this post I realized that I had the <code>HOMEBREW_NO_INSTALL_CLEANUP=1</code> flag enabled on my system.</p></blockquote>

<p>My system (MacOS) is getting more cluttered the more I use it. I&#39;m sure you can relate. If you&#39;re using <a href="https://brew.sh/">Brew</a> as your package manager (which you should ðŸ˜‰), you might want to consider running the following command:</p>

<p><code>
brew cleanup -s
</code></p>

<p>For some reason this failed after some time with a &quot;directory not found&quot; error, but you can just run it again and it will continue cleaning up old caches. Once it was done, this freed up <strong>40 GB of disk space</strong> on my system. It might make sense to run this as a cronjob? Either way, I just wanted to jot this down before I enevitably forget this, as usual.</p>]]>
            </description>
        </item>
        <item>
            <title>
                Beware of base64 encoded strings
            </title>
            <guid>
                https://garrit.xyz/posts/2024-04-15-beware-of-base64-encoded-strings
            </guid>
            <link>
                https://garrit.xyz/posts/2024-04-15-beware-of-base64-encoded-strings?utm_source=rss
            </link>
            <pubDate>
                Mon, 15 Apr 2024 00:00:00 +0000
            </pubDate>
            <description>
                <![CDATA[<p>I just encountered a fun little bug that I thought is worth sharing.</p>

<p><strong>TL;DR</strong>: the base64 util breaks lines after a certain number of columns. Use a <a href="https://www.man7.org/linux/man-pages/man1/base64.1.html">flag</a> to specify &quot;don&#39;t break&quot;. Here&#39;s the commit that fixes the issue:</p>

<p>&lt;img width=&quot;1588&quot; alt=&quot;image (3)&quot; src=&quot;https://github.com/garritfra/garrit.xyz/assets/32395585/dba76692-c89f-44da-b70a-f6732a406d75&quot;&gt;</p>

<p>It started when we noticed that a cronjob that used wget to regularly call an endpoint failed on one specific environment. The endpoint uses <a href="https://en.wikipedia.org/wiki/Basic_access_authentication">Basic Auth</a>, which is essentially a header with a <a href="https://en.wikipedia.org/wiki/Base64">Base64</a> encoded representation of a username and password. <a href="https://curl.se/">Curl</a> has this functionality <a href="https://curl.se/docs/manpage.html#-u">built in</a>, but to keep the attack surface as small as possible, we decided to stick to <a href="https://www.gnu.org/software/wget/">wget</a>, which is part of busybox, to keep the container image size under 1 MB (!). After all, all we want to do is ping an endpoint.</p>

<p>This is the command we used up to this point:</p>

<p><code>
wget --post-data=&quot;&quot; -O - --header=&quot;Authorization: Basic $(echo -n $BASIC_AUTH_USERNAME:$BASIC_AUTH_PASSWORD | base64)&quot; http://endpoint:8080/v1/cache
</code></p>

<p>We noticed that the request worked fine on non-prod environments, but it failed on production with the following error:</p>

<p><code>
The HTTP header line [b2verlk1rwjsnutbcapkjh==] does not conform to RFC 7230. The request has been rejected.
</code></p>

<p>After digging around for a while and separating out the individual pieces of the commands, I noticed that the subcommand to build the header value (<code>echo -n $BASIC_AUTH_USERNAME:$BASIC_AUTH_PASSWORD | base64</code>) behaved differently on prod vs. non-prod. The password on prod is way longer compared to the other environments. Let&#39;s run this command with a short input:</p>

<p><code>sh
/ $ echo -n someuser:somepassword | base64
c29tZXVzZXI6c29tZXBhc3N3b3Jk
/ $
</code></p>

<p>And again with a long input:</p>

<p><code>sh
/ $ echo -n someuser:somepasswordthatswaylongerthanthefirstonebutalsoverysecureandsafe | base64
c29tZXVzZXI6c29tZXBhc3N3b3JkdGhhdHN3YXlsb25nZXJ0aGFudGhlZmlyc3RvbmVidXRhbHNv
dmVyeXNlY3VyZWFuZHNhZmU=
/ $
</code></p>

<p>Bingo! There&#39;s a rogue newline character in the output of <code>base64</code>. The fix is very straight-forward. Using the <code>-w0</code> <a href="https://www.man7.org/linux/man-pages/man1/base64.1.html">flag for base64</a>, we can force the output to be on the same line:</p>

<p><code>
/ $ echo -n someuser:somepasswordthatswaylongerthanthefirstonebutalsoverysecureandsafe | base64 -w0
c29tZXVzZXI6c29tZXBhc3N3b3JkdGhhdHN3YXlsb25nZXJ0aGFudGhlZmlyc3RvbmVidXRhbHNvdmVyeXNlY3VyZWFuZHNhZmU=
</code></p>

<p>This eventually fixed the issue. Not something I would&#39;ve ever thought of!</p>]]>
            </description>
        </item>
        <item>
            <title>
                A simple search bar
            </title>
            <guid>
                https://garrit.xyz/posts/2024-04-11-a-simple-search-bar
            </guid>
            <link>
                https://garrit.xyz/posts/2024-04-11-a-simple-search-bar?utm_source=rss
            </link>
            <pubDate>
                Thu, 11 Apr 2024 00:00:00 +0000
            </pubDate>
            <description>
                <![CDATA[<p>I just added a simple search bar to my <a href="/links">&quot;More ...&quot;</a> page. It just redirects to a <a href="https://duckduckgo.com">DuckDuckGo</a> search with your search term and limits it to my site. Simple, yet effective!</p>

<p>The inspiration for this feature came from <a href="https://smeso.it/">Salvatore Mesoraca</a>&#39;s site. Here&#39;s the snippet, feel free to steal it:</p>

<p><code>jsx
&lt;form className=&quot;search&quot; method=&quot;get&quot; action=&quot;https://duckduckgo.com/&quot; target=&quot;_blank&quot;&gt;
    &lt;input id=&quot;search&quot; type=&quot;search&quot; name=&quot;q&quot; placeholder=&quot;Search via DDG&quot; /&gt;
    &lt;input type=&quot;hidden&quot; name=&quot;sites&quot; value=&quot;garrit.xyz&quot; /&gt;
    &lt;input type=&quot;submit&quot; value=&quot;Search&quot; /&gt;
&lt;/form&gt;
</code></p>

<h2>Try it out</h2>

<p>Try searching for anything!</p>

<p>&lt;form className=&quot;search&quot; method=&quot;get&quot; action=&quot;https://duckduckgo.com/&quot; target=&quot;_blank&quot;&gt;
    &lt;input id=&quot;search&quot; type=&quot;search&quot; name=&quot;q&quot; placeholder=&quot;Search via DDG&quot; /&gt;
    &lt;input type=&quot;hidden&quot; name=&quot;sites&quot; value=&quot;garrit.xyz&quot; /&gt;
    &lt;input type=&quot;submit&quot; value=&quot;Search&quot; /&gt;
&lt;/form&gt;</p>]]>
            </description>
        </item>
        <item>
            <title>
                Pandoc: Convert links to footnotes (the easy way)
            </title>
            <guid>
                https://garrit.xyz/posts/2024-04-04-pandoc-convert-links-to-footnotes-the-easy-way
            </guid>
            <link>
                https://garrit.xyz/posts/2024-04-04-pandoc-convert-links-to-footnotes-the-easy-way?utm_source=rss
            </link>
            <pubDate>
                Thu, 04 Apr 2024 00:00:00 +0000
            </pubDate>
            <description>
                <![CDATA[<p>Pandoc has <a href="https://pandoc.org/MANUAL.html#links">a feature</a> to covert links to footnotes. Unfortunately, this only applies to LaTeX documents. Since I want to stay away from LaTeX for reasons of bloat, I was looking for a more universal approach.</p>

<p>First, I encountered <a href="https://stackoverflow.com/questions/33900067/pandoc-filter-to-add-footnotes-to-links">this</a> thread suggesting to use a regular <a href="https://pandoc.org/filters.html">Pandoc filter</a>. This has one downside though: you need a Haskell toolchain on your system. So I moved on ... </p>

<p>I eventually stumbled across <a href="https://github.com/jgm/pandoc/discussions/9415">this</a> thread, explaining how to do the same thing but with a Lua filter instead of Haskell. Since Lua is embedded into Pandoc, you don&#39;t need to install anything. Hooray for embeddable languages!</p>

<p>Simply place the following snippet into file (<code>/filters/link-to-footnote.lua</code> for example):</p>

<p><code>lua
function Link(link)
    link.content:insert(pandoc.Note(link.target))
    return link.content
end
</code></p>

<blockquote><p><em>Note</em>: If you want to keep the original hyperlink in tact, replace the <code>return link.content</code> with <code>return link</code>.</p></blockquote>

<p>And add the following flag to your Pandoc build command:</p>

<p><code></code>`sh</p>

<h1>!/bin/sh</h1>

<p>pandoc text.md
    -o book.epub \
    --lua-filter=filters/link-to-footnote.lua \ # &lt;-- This one
    --metadata-file metadata.yaml \
    --standalone \
    # ...
<code></code>`</p>

<p>After compiling the document, you should now see that each link has a footnote with the link text.</p>]]>
            </description>
        </item>
        <item>
            <title>
                A better publishing workflow for static blogs
            </title>
            <guid>
                https://garrit.xyz/posts/2024-01-06-a-better-publishing-workflow-for-static-blogs
            </guid>
            <link>
                https://garrit.xyz/posts/2024-01-06-a-better-publishing-workflow-for-static-blogs?utm_source=rss
            </link>
            <pubDate>
                Sat, 06 Jan 2024 00:00:00 +0000
            </pubDate>
            <description>
                <![CDATA[<p>In my <a href="/posts/2023-12-23-100daystooffload-i-made-it">post</a> celebrating the completion of my <code>#100DaysToOffload</code> challenge, I teased that &quot;I built myself a handy script that turns the contents of a GitHub issue into a pull request, ready to be merged as a blog post&quot;. I didn&#39;t believe this was such a big deal, but a couple of readers actually reached out to me to ask about this.</p>

<p>First, some background. My site is built using a static site generator (not that it matters, but I use <a href="https://nextjs.org/">Next.js</a>). The beauty of using a SSG is that every blog post is literally just a markdown file in <a href="https://github.com/garritfra/garrit.xyz/tree/main/content/posts">a directory</a>. </p>

<h2>The story so far</h2>

<p>Before coming up with an automation, I had to</p>

<ol><li>Copy an older post to a new file</li><li>Rename the file</li><li>Fix the metadata/frontmatter</li><li>Delete the contents of the post</li><li><strong>Write the actual post</strong></li><li>Commit the file</li></ol>

<p>Putting out content on my blog involved quite a bit of friction. I felt like there was a barrier between my thoughts and the blog.</p>

<h2>The solution</h2>

<p>I&#39;ve been looking into how I could solve this issue for quite some time. I even had thoughts to build a custom blogging backend that would commit files to the <a href="https://github.com/garritfra/garrit.xyz">repository</a>, which is of course quite silly.</p>

<p>But then it struck me: GitHub issues fully support markdown! The idea was born:</p>

<ol><li>Open an issue in the repository of this blog</li><li>Write the post</li><li>Kick off an automation that takes the content of the issue and dumps it in a new file</li><li>Create a pull request to generate a preview of the post</li><li>Merge the PR once I&#39;m done reviewing the post</li></ol>

<h2>So, how does the automation work?</h2>

<p>The magic lies in <a href="https://github.com/garritfra/garrit.xyz/blob/main/.github/workflows/publish_via_issue.yaml">this GitHub Action</a>. It is kicked off whenever the <code>action:publish</code> label is added to an issue.</p>

<p>If for some reason this link will not be there anymore in the future, this is the action as of the time of writing:</p>

<p>&lt;details&gt;
&lt;summary&gt;Expand me!&lt;/summary&gt;</p>

<p><code></code>`yaml
on:
  issues:
    types: [labeled]</p>

<p>name: Publish issue as post
jobs:
  publish-issue:
    if: github.event.label.name == &#39;action:publish&#39;
    runs-on: ubuntu-latest
    env:
      POST<em>BODY: &#39;${{ github.event.issue.body }}&#39;
    steps:
      - uses: actions/checkout@v4
      - name: Create commits
        run: |
          export POST</em>DATE=$(date +&quot;%Y-%m-%d&quot;)
          export POST<em>TITLE=&quot;${{ github.event.issue.title }}&quot;
          export POST</em>TAGS=$(echo &quot;${{ join(github.event.issue.labels.<em>.name, &#39;, &#39;) }}&quot; | grep -o &#39;tag:[^,]</em>&#39; | cut -d: -f2- | paste -sd &quot; &quot; - | sed &#39;s/ /, /g&#39;)
          export FILE<em>TITLE=$(printf &quot;$POST</em>TITLE&quot; | tr -cs &#39;[:alnum:]&#39; &#39;-&#39; | tr &#39;A-Z&#39; &#39;a-z&#39; | sed &#39;s/--/-/g&#39; | sed &#39;s/^-\|-$//g&#39;)
          export FILE<em>NAME=&quot;$POST</em>DATE-$FILE<em>TITLE.md&quot;
          export FULL</em>PATH=&quot;content/posts/$FILE_NAME&quot;
          git config user.name &#39;Publish Bot&#39;
          git config user.email &#39;publish-bot@github.com&#39;</p>

<pre><code>      cat &lt;&lt; EOF &gt; $FULL_PATH
      ---
      title: &quot;$POST_TITLE&quot;
      date: &quot;$POST_DATE&quot;
      tags: &quot;$POST_TAGS&quot;
      ---

      EOF

      echo &quot;$POST_BODY&quot; &gt;&gt; $FULL_PATH

      git add $FULL_PATH
      git commit -m &quot;Publish $POST_TITLE&quot;

  - name: Create Pull Request
    uses: peter-evans/create-pull-request@v5
    with:
      title: &quot;New Post: ${{ github.event.issue.title }}&quot;
      body: &quot;Closes #${{ github.event.issue.number }}.\n\n This PR has been generated automatically.&quot;
  - uses: actions-ecosystem/action-remove-labels@v1
    with:
      labels: action:publish</code></pre>

<p><code></code>`</p>

<p>&lt;/details&gt;</p>

<p>So, when I&#39;m done writing the post, I simply label the issue as <code>action:publish</code>, and the action turns it into a new file, commits it and ultimately opens a PR for me to review. You can see this in action by looking at <a href="https://github.com/garritfra/garrit.xyz/issues/432">the issue for this post</a>. The action also handles tags for blog posts. You can see that there are a bunch of labels on the issues that correspond to the tags of this post.</p>

<p>One additional benefit of using a static site generator is that I can generate a preview site for each pull request. So, once I&#39;m done writing and the pull request is generated, I can just wait for Netlify to build the preview to read the blog post as if it is published to the site! This is very helpful for spotting typos or formatting issues, especially if I&#39;m writing a post on my phone.</p>

<h2>Further improvements</h2>

<p>There are two things the current setup is lacking:</p>

<p>Firstly, GitHub doesn&#39;t really highlight typos when writing an issue. I&#39;m sure there are ways to address this post-publish, I just didn&#39;t get around to doing that yet.</p>

<p>Secondly, there&#39;s no sustainable way to add images to the repository this way. I have an <a href="https://github.com/garritfra/garrit.xyz/tree/main/public/assets">assets directory</a> where I put all my images for blog posts. You can paste images directly into the issue, which is really handy, but that generates a permalink on a GitHub CDN, somewhere that I don&#39;t control. For the future, it would be nice to teach the GH action to take these images and dump them into the asset directory.</p>

<h2>Conclusion</h2>

<p>Using this workflow, I can pump out ideas whenever and whereever I feel like it. It drastically reduced the time from idea to written article, which helps me organize my thoughts a lot better. I also frequently create drafts for things I want to write about but is not fully fleshed out yet.</p>]]>
            </description>
        </item>
        <item>
            <title>
                Overcoming "air hunger"
            </title>
            <guid>
                https://garrit.xyz/posts/2023-12-18-overcoming-air-hunger
            </guid>
            <link>
                https://garrit.xyz/posts/2023-12-18-overcoming-air-hunger?utm_source=rss
            </link>
            <pubDate>
                Mon, 18 Dec 2023 00:00:00 +0000
            </pubDate>
            <description>
                <![CDATA[<p>For as long as I can remember, I often had the feeling of not being able to get a full breath. I&#39;m taking deep breaths and sometimes forcing a yawn to overcome this feeling, sometimes successful, sometimes failing and trying again. This feeling gets worse the more I focus on my breath.</p>

<p>I always felt like this is somewhat uncommon, since none of my friends and family can relate to this feeling, but it wasn&#39;t worse enough to justify consulting a doctor about it either.</p>

<p>Doing some research, it seems like this phenomenon is called <a href="https://en.m.wikipedia.org/wiki/Shortness_of_breath">dyspnea</a>, or &quot;air hunger&quot;. Some guy even made <a href="https://airhunger.org/">a website</a> about it. In a nutshell, it is caused by your body not being able to regulate carbon levels in your blood, which leads to an urge to breath unnaturally.</p>

<p>In a <a href="https://m.youtube.com/watch?v=XliOGg8Tl98">video</a>, the author points out that this might be caused by irregular breathing patterns. Indeed, I often find myself breathing through the mouth or sitting in awkward positions with a humpback when the symptoms are at its worst. In fact, what led me to look this up was because I was annoyed by the feeling while I&#39;m laying in bed staring down at my screen, which is a very unnatural position.</p>

<p>A simple trick to get into a more regular breathing pattern is apparently to force yourself to breathe through the nose. Mouth breathing lets your body take in way more air than you need, which throws off the balance of the carbon levels in your lungs.</p>

<p>It seems like nose breathing does work very well. Where I&#39;ve just been struggling with air hunger, once I forced myself to nose breathe, the urge to breathe doesn&#39;t come nearly as often anymore.</p>

<p>These are just my results after some quick research. The topic of short breathing seems to be quite broad. Perhaps you&#39;re struggling with this as well. In that case, I hope this post was helpful to you!</p>

<hr/>

<p>This is post 095 of <a href="https://100daystooffload.com/">#100DaysToOffload</a>.</p>]]>
            </description>
        </item>
        <item>
            <title>
                Tracking SQLite Database Changes in Git
            </title>
            <guid>
                https://garrit.xyz/posts/2023-11-01-tracking-sqlite-database-changes-in-git
            </guid>
            <link>
                https://garrit.xyz/posts/2023-11-01-tracking-sqlite-database-changes-in-git?utm_source=rss
            </link>
            <pubDate>
                Wed, 01 Nov 2023 00:00:00 +0000
            </pubDate>
            <description>
                <![CDATA[<blockquote><p><strong>Note</strong>: This post stirred up some interesting discussions on <a href="https://news.ycombinator.com/item?id=38110286">HackerNews</a> and <a href="https://lobste.rs/s/gnv9ho/tracking_sqlite_database_changes_git">Lobste.rs</a>.</p></blockquote>

<p>SQLite stores data in binary. If you run <code>cat mydb.sqlite</code>, you&#39;ll see a bunch of gibberish that doesn&#39;t resemble structured data at all. If you want to track changes and updates to a database using Git, you won&#39;t be able to see full diffs by default. You&#39;ll see that the file has changed, but not what changed exactly:</p>

<p><code>diff
diff --git a/mydb.sqlite b/mydb.sqlite
index f412c72..8f49ea5 100644
Binary files a/mydb.sqlite and b/mydb.sqlite differ
</code></p>

<p>So, is there a way around that? Turns out: there is! Here&#39;s a diff between two states of the SQLite database of <a href="https://www.gnucash.org/index.phtml">GnuCash</a>, which I&#39;m currently trying out to manage my finances. I&#39;ll explain how I got this diff afterwards:</p>

<p><code>diff
diff --git a/garritfranke.gnucash b/garritfranke.gnucash
index f412c72..8f49ea5 100644
--- a/garritfranke.gnucash
+++ b/garritfranke.gnucash
@@ -100,18 +100,22 @@ INSERT INTO accounts VALUES(&#39;ca11987c1c804da4b47b70d0fda87f10&#39;,&#39;Strom&#39;,&#39;EXPENSE&#39;
 INSERT INTO accounts VALUES(&#39;b1674455d6ec495c8898bcfb65ef100c&#39;,&#39;Template Root&#39;,&#39;ROOT&#39;,NULL,0,0,NULL,&#39;&#39;,&#39;&#39;,0,0);
+INSERT INTO accounts VALUES(&#39;9d2959ea65fc4f29b02dbc593fa9598a&#39;,&#39;Ausgleichskonto-EUR&#39;,&#39;BANK&#39;,&#39;26cc1292cf3e4f9584c71e7b3ec28479&#39;,100,0,&#39;39e1c61538e24572abfcf0f3f72022ac&#39;,&#39;&#39;,&#39;&#39;,0,0);
 CREATE TABLE budgets(guid text(32) PRIMARY KEY NOT NULL, name text(2048) NOT NULL, description text(2048), num_periods integer NOT NULL);
 CREATE TABLE prices(guid text(32) PRIMARY KEY NOT NULL, commodity_guid text(32) NOT NULL, currency_guid text(32) NOT NULL, date text(19) NOT NULL, source text(2048), type text(2048), value_num bigint NOT NULL, value_denom bigint NOT NULL);
 CREATE TABLE transactions(guid text(32) PRIMARY KEY NOT NULL, currency_guid text(32) NOT NULL, num text(2048) NOT NULL, post_date text(19), enter_date text(19), description text(2048));
+INSERT INTO transactions VALUES(&#39;db9eff5ec00145f293c85391becbefa8&#39;,&#39;26cc1292cf3e4f9584c71e7b3ec28479&#39;,&#39;&#39;,&#39;2023-11-01 10:59:00&#39;,&#39;2023-11-01 11:36:23&#39;,&#39;TEST&#39;);
 INSERT INTO splits VALUES(&#39;e45aeb0ac0274c6483f8deb2e7ad3743&#39;,&#39;10cecb081ac24ab5a369c93f96d293da&#39;,&#39;d229160352064f8c80090e0a10a57d9c&#39;,&#39;&#39;,&#39;Rechnung&#39;,&#39;n&#39;,&#39;1970-01-01 00:00:00&#39;,0,100,0,100,NULL);
 INSERT INTO splits VALUES(&#39;bb9d2818bdc14be9bb916f3efd82e77d&#39;,&#39;10cecb081ac24ab5a369c93f96d293da&#39;,&#39;1d93d1e67aed4320bb228c16f4e28092&#39;,&#39;&#39;,&#39;Rechnung&#39;,&#39;n&#39;,&#39;1970-01-01 00:00:00&#39;,25000,100,25000,100,&#39;b94c643ddcda48bcb7fc58626452e825&#39;);
 INSERT INTO splits VALUES(&#39;62747f45556740fe836c9f2180fe70c9&#39;,&#39;10cecb081ac24ab5a369c93f96d293da&#39;,&#39;4d6616d8c6524ead86641559539caf50&#39;,&#39;&#39;,&#39;Rechnung&#39;,&#39;n&#39;,&#39;1970-01-01 00:00:00&#39;,-25000,100,-25000,100,NULL);
+INSERT INTO splits VALUES(&#39;029f58c4d85c497c8e06ad4e52090033&#39;,&#39;db9eff5ec00145f293c85391becbefa8&#39;,&#39;a0f46eb546e34555ab4d0d3cc32c320f&#39;,&#39;&#39;,&#39;&#39;,&#39;n&#39;,&#39;1970-01-01 00:00:00&#39;,-10000,100,-10000,100,NULL);
+INSERT INTO splits VALUES(&#39;433a48cfdd314c94a105b5db9e7839de&#39;,&#39;db9eff5ec00145f293c85391becbefa8&#39;,&#39;9d2959ea65fc4f29b02dbc593fa9598a&#39;,&#39;&#39;,&#39;&#39;,&#39;n&#39;,&#39;1970-01-01 00:00:00&#39;,10000,100,10000,100,NULL);
 CREATE TABLE slots(id integer PRIMARY KEY AUTOINCREMENT NOT NULL, obj_guid text(32) NOT NULL, name text(4096) NOT NULL, slot_type integer NOT NULL, int64_val bigint, string_val text(4096), 
 INSERT INTO slots VALUES(84,&#39;d9d25d75a993434597d988baa65670bb&#39;,&#39;job-rate&#39;,3,0,NULL,NULL,&#39;1970-01-01 00:00:00&#39;,NULL,250,1,NULL);
 INSERT INTO slots VALUES(85,&#39;38cde72240424e8b9e3ab5d4852c9cf0&#39;,&#39;job-rate&#39;,3,0,NULL,NULL,&#39;1970-01-01 00:00:00&#39;,NULL,100,1,NULL);
+INSERT INTO slots VALUES(88,&#39;db9eff5ec00145f293c85391becbefa8&#39;,&#39;date-posted&#39;,10,0,NULL,NULL,&#39;1970-01-01 00:00:00&#39;,NULL,0,1,&#39;20231101&#39;);
 CREATE TABLE recurrences(id integer PRIMARY KEY AUTOINCREMENT NOT NULL, obj_guid text(32) NOT NULL, recurrence_mult integer NOT NULL, recurrence_period_type text(2048) NOT NULL, recurrence_period_start text(8) NOT NULL, recurrence_weekend_adjust text(2048) NOT NULL);
 CREATE TABLE schedxactions(guid text(32) PRIMARY KEY NOT NULL, name text(2048), enabled integer NOT NULL, start_date text(8), end_date text(8), last_occur text(8), num_occur integer NOT NULL, rem_occur integer NOT NULL, auto_create integer NOT NULL, auto_notify integer NOT NULL, adv_creation integer NOT NULL, adv_notify integer NOT NULL, instance_count integer NOT NULL, template_act_guid text(32) NOT NULL);
 CREATE TABLE lots(guid text(32) PRIMARY KEY NOT NULL, account_guid text(32), is_closed integer NOT NULL);
@@ -234,7 +239,7 @@ INSERT INTO taxtable_entries VALUES(3,&#39;1d459b285fca4de3bb4659744dc0cec5&#39;,&#39;d22916
 INSERT INTO taxtable_entries VALUES(5,&#39;6def0d3a788d414b818ecdb29ba3dcd1&#39;,&#39;d229160352064f8c80090e0a10a57d9c&#39;,0,100000,2);
 CREATE TABLE vendors(guid text(32) PRIMARY KEY NOT NULL, name text(2048) NOT NULL, id text(2048) NOT NULL, notes text(2048) NOT NULL, currency text(32) NOT NULL, active integer NOT NULL, tax_override integer NOT NULL, addr_name text(1024), addr_addr1 text(1024), addr_addr2 text(1024), addr_addr3 text(1024), addr_addr4 text(1024), addr_phone text(128), addr_fax text(128), addr_email text(256), terms text(32), tax_inc text(2048), tax_table text(32));
 DELETE FROM sqlite_sequence;
-INSERT INTO sqlite_sequence VALUES(&#39;slots&#39;,87);
+INSERT INTO sqlite_sequence VALUES(&#39;slots&#39;,88);
 INSERT INTO sqlite_sequence VALUES(&#39;taxtable_entries&#39;,5);
 CREATE INDEX tx_post_date_index ON transactions(post_date);
 CREATE INDEX splits_tx_guid_index ON splits(tx_guid);
</code></p>

<p>First, add a diff type called &quot;sqlite3&quot; to your config. The simplest way is to just run these commands:</p>

<p><code>shell
git config diff.sqlite3.binary true
git config diff.sqlite3.textconv &quot;echo .dump | sqlite3&quot;
</code></p>

<p>Alternatively, you can add this snippet to your <code>~/.gitconfig</code> or <code>.git/config</code> in your repository:</p>

<p><code>gitconfig
[diff &quot;sqlite3&quot;]
        binary = true
        textconv = &quot;echo .dump | sqlite3&quot;
</code></p>

<p>Next, create a file called <code>.gitattributes</code> if it&#39;s not already present and add this line:</p>

<p><code>gitattributes
*.sqlite diff=sqlite3
</code></p>

<blockquote><p>Note that the filename (<code>*.sqlite</code>) may differ from your setup. In my case for example, it should match files with <code>*.gnucash</code>.</p></blockquote>

<p>And that&#39;s about it! The next time you run <code>git diff</code> or any other command that produces a diff on a sqlite file, you&#39;ll see a nicely formatted diff of the changes.</p>

<h3>Source</h3>

<p>https://stackoverflow.com/a/21789167</p>

<hr/>

<p>This is post 084 of <a href="https://100daystooffload.com/">#100DaysToOffload</a>.</p>]]>
            </description>
        </item>
        <item>
            <title>
                Organizing multiple Git identities
            </title>
            <guid>
                https://garrit.xyz/posts/2023-10-13-organizing-multiple-git-identities
            </guid>
            <link>
                https://garrit.xyz/posts/2023-10-13-organizing-multiple-git-identities?utm_source=rss
            </link>
            <pubDate>
                Fri, 13 Oct 2023 00:00:00 +0000
            </pubDate>
            <description>
                <![CDATA[<p>Here&#39;s a quick tip on how to manage multiple Git identities (e.g. personal, work, client1, client2).</p>

<p>I organize my Git repos in three levels. My personal projects live in a <code>~/sources</code> directory. All my work projects live in <code>~/work</code>. This is the first level.</p>

<p>Level 2 is the client, e.g. <code>~/work/client1</code>. Naturally, level 3 is the project repository: <code>~/work/client1/foo-api</code>.</p>

<p>This is how my work directory is organized:</p>

<p><code>
/Users/garrit/work
â”œâ”€â”€ client1
â”‚   â”œâ”€â”€ foo-api
â”‚   â”œâ”€â”€ foo-ios
â”‚   â””â”€â”€ foo-android
â””â”€â”€ client2
    â”œâ”€â”€ bar-ios
    â””â”€â”€ bar-middleware
</code></p>

<p>Now, say that <code>client2</code> demands that we commit with a different identity than our default work email. Besides that, you probably also have a personal email address for your own projects. How do you manage that?</p>

<h2>.gitconfig includes</h2>

<p>The global configuration file for Git is <code>~/.gitconfig</code>. If you&#39;ve ever set a parameter like <code>git config user.name &quot;Foo Bar&quot;</code>: this is where it ended up.</p>

<p>One awesome feature of the .gitconfig file is that you can <strong>conditionally include other config files</strong>, and this is what does the trick. Here&#39;s my <code>~/.gitconfig</code> file:</p>

<p><code></code>`ini
[user]
    name = Garrit Franke
    email = garrit@slashdev.space</p>

<p>[includeIf &quot;gitdir:~/work/&quot;]
    path = ~/.gitconfig-work</p>

<p>[includeIf &quot;gitdir:~/work/client2/&quot;]
    path = ~/.gitconfig-client2</p>

<p>[includeIf &quot;gitdir:~/sources/&quot;]
    path = ~/.gitconfig-personal</p>

<h1>...</h1>

<p><code></code>`</p>

<p>By default, my name and email are always set to my personal identity. I also store some other global settings here, but those are not relevant for this post. If the repository is located inside the <code>~/work</code> directory, a file named <code>~/.gitconfig-work</code> is included. This is just another gitconfig file. This is what that looks like in my case:</p>

<p><code></code>`ini
[user]
    name = Garrit Franke
    signingkey = 12345678
    email = garrit@work.de</p>

<p>[commit]
    gpgsign = true
<code></code>`</p>

<p>I hope you&#39;ll see where this is going. For every identity, you keep a separate gitconfig file and include it in the main <code>~/.gitconfig</code>. Crucially, this requires you to organize your repositories grouped by client.</p>

<p>This trick has simplified my project onboarding quite a bit. No more &quot;You forgot to update your Email Address&quot; requests from clients!</p>

<hr/>

<p>This is post 083 of <a href="https://100daystooffload.com/">#100DaysToOffload</a>.</p>]]>
            </description>
        </item>
        <item>
            <title>
                Single Page Applications on GitHub Pages
            </title>
            <guid>
                https://garrit.xyz/posts/2023-06-01-single-page-applications-on-github-pages
            </guid>
            <link>
                https://garrit.xyz/posts/2023-06-01-single-page-applications-on-github-pages?utm_source=rss
            </link>
            <pubDate>
                Thu, 01 Jun 2023 00:00:00 +0000
            </pubDate>
            <description>
                <![CDATA[<p>My latest project, <a href="https://sendpasswords.net/">sendpasswords.net</a> is a <a href="https://developer.mozilla.org/en-US/docs/Glossary/SPA">Single Page Application</a> deployed on GitHub Pages.</p>

<p>GitHub Pages is configured in a way to host static HTML files without any bells and whistles. This means that if you try to fetch a document that&#39;s <em>not</em> the index, for example <code>/foo</code>, the server will try to load the file with that name. </p>

<p>By nature, SPAs only consist of a single HTML entry point (<code>index.html</code> in most cases). It&#39;s responsible for routing the user to the correct page if there are multiple paths. And here&#39;s the crux: if the user tries to load <code>/foo</code>, he will not land at the SPA entry point. Instead, he will see a <code>404</code> error.</p>

<h2>The solution</h2>

<p>A <code>404</code> response will automatically return a file called <code>404.html</code>, which we can use to our advantage. After building the application, simply copy the <code>index.html</code> to <code>404.html</code>, as demonstrated by <a href="https://github.com/garritfra/sendpasswords.net/commit/66bdb68c229a3ac3386f7816a746155e658eb586">this commit</a>. This will use <code>index.html</code> to serve the application on the root level, and <code>404.html</code> to load <em>the same app</em> if the page doesn&#39;t exist as a file. Whether the <code>index.html</code> is needed if there&#39;s already a <code>404.html</code> is up to you. I left it in to make clear that this is just a workaround.</p>

<p>This is a <a href="https://stackoverflow.com/a/69308662/9046809">well known</a> workaround, but I wanted to bring some extra awareness to it, since it&#39;s a problem I ran into a couple of times so far. Happy SPAing!</p>

<hr/>

<p>This is post 069 (nice) of <a href="https://100daystooffload.com/">#100DaysToOffload</a>.</p>]]>
            </description>
        </item>
        <item>
            <title>
                Migrating Homeassistant from SD to SSD
            </title>
            <guid>
                https://garrit.xyz/posts/2023-04-27-migrating-homeassistant-from-sd-to-ssd
            </guid>
            <link>
                https://garrit.xyz/posts/2023-04-27-migrating-homeassistant-from-sd-to-ssd?utm_source=rss
            </link>
            <pubDate>
                Thu, 27 Apr 2023 00:00:00 +0000
            </pubDate>
            <description>
                <![CDATA[<p>I finally got frustrated with the performance of my Raspberry Pi 4 running Homeassistant on a SD card, so I went ahead and got an SSD.</p>

<p>The migration was <strong>very</strong> easy:</p>

<ol><li>Create and download a full backup through the UI</li><li>Flash Homeassistant onto the SSD</li><li>Remove the SD card and plug the SSD into a USB 3.0 port of the Pi</li><li>Boot</li><li>Go through the onboarding procedure</li><li>Restore Backup</li><li>Profit</li></ol>

<p>It worked like a charm! The speed has improved A LOT, and everything was set up as it should be. </p>

<p>...Until we turned on the lights in the livingroom. My ZigBee-dongle, plugged into another USB port, wasn&#39;t able to communicate with the devices on the network.</p>

<p>After some digging around, I came across several threads stating that an SSD over USB 3.0 apparently creates a lot of interference to surrounding hardware, including my ZigBee dongle. The fix was simple: either get an extension port for the dongle, or plug the SSD into a USB 2.0 port of the Pi. Since I didn&#39;t have an extension cord to get the dongle far away enough from the SSD, I went with the latter option for now. And that fixed it! The performance was much worse, but still better than the SD I used before. My next step will be to grab an extension cord from my parents. I&#39;m sure they won&#39;t mind.</p>

<p>I hope this helps!</p>

<hr/>

<p>This is post 066 of <a href="https://100daystooffload.com/">#100DaysToOffload</a>.</p>]]>
            </description>
        </item>
    </channel>
</rss>