<?xml version="1.0"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>
            garrit.xyz
        </title>
        <link>
            https://garrit.xyz
        </link>
        <description>
            Garrit Franke
        </description>
        <language>
            en
        </language>
        <lastBuildDate>
            Mon, 15 Apr 2024 00:00:00 +0000
        </lastBuildDate>
        <item>
            <title>
                Beware of base64 encoded strings
            </title>
            <guid>
                https://garrit.xyz/posts/2024-04-15-beware-of-base64-encoded-strings
            </guid>
            <link>
                https://garrit.xyz/posts/2024-04-15-beware-of-base64-encoded-strings?utm_source=rss
            </link>
            <pubDate>
                Mon, 15 Apr 2024 00:00:00 +0000
            </pubDate>
            <description>
                <![CDATA[<p>I just encountered a fun little bug that I thought is worth sharing.</p>

<p><strong>TL;DR</strong>: Here&#39;s the commit that fixes the issue:</p>

<p>&lt;img width=&quot;1588&quot; alt=&quot;image (3)&quot; src=&quot;https://github.com/garritfra/garrit.xyz/assets/32395585/dba76692-c89f-44da-b70a-f6732a406d75&quot;&gt;</p>

<p>It started when we noticed that a cronjob that used wget to regularly call an endpoint failed on one specific environment. The endpoint uses <a href="https://en.wikipedia.org/wiki/Basic_access_authentication">Basic Auth</a>, which is essentially a header with a <a href="https://en.wikipedia.org/wiki/Base64">Base64</a> encoded representation of a username and password. <a href="https://curl.se/">Curl</a> has this functionality <a href="https://curl.se/docs/manpage.html#-u">built in</a>, but to keep the attack surface as small as possible, we decided to stick to <a href="https://www.gnu.org/software/wget/">wget</a>, which is part of busybox, to keep the container image size under 1 MB (!). After all, all we want to do is ping an endpoint.</p>

<p>This is the command we used up to this point:</p>

<p><code>
wget --post-data=&quot;&quot; -O - --header=&quot;Authorization: Basic $(echo -n $BASIC_AUTH_USERNAME:$BASIC_AUTH_PASSWORD | base64)&quot; http://endpoint:8080/v1/cache
</code></p>

<p>We noticed that the request worked fine on non-prod environments, but it failed on production with the following error:</p>

<p><code>
The HTTP header line [b2verlk1rwjsnutbcapkjh==] does not conform to RFC 7230. The request has been rejected.
</code></p>

<p>After digging around for a while and separating out the individual pieces of the commands, I noticed that the subcommand to build the header value (<code>echo -n $BASIC_AUTH_USERNAME:$BASIC_AUTH_PASSWORD | base64</code>) behaved differently on prod vs. non-prod. The password on prod is way longer compared to the other environments. Let&#39;s run this command with a short input:</p>

<p><code>sh
/ $ echo -n someuser:somepassword | base64
c29tZXVzZXI6c29tZXBhc3N3b3Jk
/ $
</code></p>

<p>And again with a long input:</p>

<p><code>sh
/ $ echo -n someuser:somepasswordthatswaylongerthanthefirstonebutalsoverysecureandsafe | base64
c29tZXVzZXI6c29tZXBhc3N3b3JkdGhhdHN3YXlsb25nZXJ0aGFudGhlZmlyc3RvbmVidXRhbHNv
dmVyeXNlY3VyZWFuZHNhZmU=
/ $
</code></p>

<p>Bingo! There&#39;s a rogue newline character in the output of <code>base64</code>. The fix is very straight-forward. Using the <code>-w0</code> <a href="https://www.man7.org/linux/man-pages/man1/base64.1.html">flag for base64</a>, we can force the output to be on the same line:</p>

<p><code>
/ $ echo -n someuser:somepasswordthatswaylongerthanthefirstonebutalsoverysecureandsafe | base64 -w0
c29tZXVzZXI6c29tZXBhc3N3b3JkdGhhdHN3YXlsb25nZXJ0aGFudGhlZmlyc3RvbmVidXRhbHNvdmVyeXNlY3VyZWFuZHNhZmU=
</code></p>

<p>This eventually fixed the issue. Not something I would&#39;ve ever thought of!</p>]]>
            </description>
        </item>
        <item>
            <title>
                Beating Elden Ring
            </title>
            <guid>
                https://garrit.xyz/posts/2024-04-10-beating-elden-ring
            </guid>
            <link>
                https://garrit.xyz/posts/2024-04-10-beating-elden-ring?utm_source=rss
            </link>
            <pubDate>
                Wed, 10 Apr 2024 00:00:00 +0000
            </pubDate>
            <description>
                <![CDATA[<blockquote><p><strong>⚠️ WARNING ⚠️</strong>: This post contains a lot of spoilers for the game Elden Ring.</p></blockquote>

<p>So, I just beat Elden Ring. It took me 120 hours and, coincidentally, I was level 120 when I beat the final boss. That damn final boss... but more on that later.</p>

<p>Elden Ring won me over instantly, even though I&#39;ve never played any of the other Souls games. After beating <a href="https://de.wikipedia.org/wiki/The_Legend_of_Zelda:_Breath_of_the_Wild">Breath of the Wild</a>, I called it my favorite game. I just needed more games like this. When Elden Ring came out, people compared The Lands Between to the open world of Hyrule, and I quickly agreed. The freedom these games give you is absolutely unbeaten. You almost never really get &quot;stuck&quot; on something. You can always wonder off and explore until you&#39;re ready to take on the fight.</p>

<p>After about 50 hours into playing Elden Ring, I kind of lost my focus and stopped playing for a while. It was too huge of a game to beat at the time, so I gave up.</p>

<p>But then, <a href="https://de.wikipedia.org/wiki/The_Legend_of_Zelda:_Tears_of_the_Kingdom">Tears of the Kingdom</a> came out and doubled up on the world of Hyrule. I absolutely adored this game. I spent day and night playing until I finally beat it. This game also motivated me to beat Elden Ring one more time. Despite failing over and over, each play session gave me a feeling of progression. I might not have beaten a boss yet, but there was always something happening the side that got me closer to beating it. Be it exploring and getting better gear or learning as much as I can about a boss to find ways to deal damange, I always got a small step closer to my goal. I&#39;d go as far as to say I never felt so determined to reach a goal ever before in my life.</p>

<p>The boss fights in Elden Ring are obviously extremely difficult, but they&#39;re always fair. The bosses in this game never make mistakes, you&#39;re the one that screwed up. You just keep failing and failing, but with each run, you learn something new about the fight that makes it easier in the next run. And when you finally overcoming this challenge gives you a feeling of accomplishment like nothing else could.</p>

<p>What I didn&#39;t realize in the beginning of my playthough is how extremely well rounded the world and the lore of this game is. I spent days and nights indulging myself in the lore through numerous YouTube videos, guides and Wikis. Only then did I begin to understand the scale of this game. Every action of each character, every building and every item fits in the grand scheme of the world.</p>

<p>Going out of this, the biggest thing that stuck with me is the determination. Failing is part of your life, and that is okay. No matter how daunting a task is, there&#39;s <strong>always</strong> a way to overcome it. The Elden Beast is the final boss of the game, and it&#39;s also where I spent about a quarter of my playtime. This thing has absurd attacks, immense health, and did I mention that you have to beat it after beating another extremely difficult boss, without being able to top up your health? This fight is ridiculous. I spent multiple weeks trying to beat it. I was really close to giving up, but as I mentioned earlier, each run gets you a tiny bit closer to the finish line, so I pushed through. I refined my build, I leveled up my stats and I learned how to dance with the beast. Eventually, I won the fight not by luck, but by determination. I now feel like I understand every attack well enough to dodge it. My mind was on autopilot when I beat it.</p>

<p>Knowing this much about a game didn&#39;t teach me any practical skills. There&#39;s nothing I can do now that I couldn&#39;t do before I knew that Rykard (Lord of Blasphemy), son of Rennala and Radagon (also known as Queen Marika), chose to go against the Erdtree and eventually fed himself to a serpent to devour the entire world (which you prevented). But there&#39;s something about this game that left me craving for more. It&#39;s truly a masterpiece.</p>

<h2>Bonus</h2>

<p>In case you&#39;re interested, I uploaded some of the bossfights during my playthrough in this YouTube playlist:</p>

<p>&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/videoseries?si=j1Ue2lrrLy1JTOM9&amp;amp;list=PLS8TKBZz1x5S6ojf24SMF1h_HYb4AyTxc&quot; title=&quot;YouTube video player&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&quot; referrerpolicy=&quot;strict-origin-when-cross-origin&quot; allowfullscreen&gt;&lt;/iframe&gt;</p>]]>
            </description>
        </item>
        <item>
            <title>
                #100DaysToOffload: I made it!
            </title>
            <guid>
                https://garrit.xyz/posts/2023-12-23-100daystooffload-i-made-it
            </guid>
            <link>
                https://garrit.xyz/posts/2023-12-23-100daystooffload-i-made-it?utm_source=rss
            </link>
            <pubDate>
                Sat, 23 Dec 2023 00:00:00 +0000
            </pubDate>
            <description>
                <![CDATA[<p>This marks post 100 of <a href="https://100daystooffload.com">#100DaysToOffload</a>. These last couple of days, I&#39;ve been sprinting towards the finish line with one post every day to finish the challenge until the end of the year. And I finally made it!</p>

<p>I started this challenge with <a href="https://garrit.xyz/posts/2021-01-11-100daystooffload">this</a> post on January 11th, 2021, which means it took me almost three full years to finish it. The original challenge was to write 100 posts in <strong>one</strong> year, so I&#39;m way overdue. 😅 But that doesn&#39;t make me less proud to finish it!</p>

<p>If you&#39;re interested, you can find the list of all 100 of my posts <a href="https://garrit.xyz/posts?tags=100DaysToOffload">here</a>.</p>

<h2>What I learned</h2>

<p>Before starting this challenge, I sometimes struggled with putting out content on this blog. It felt like each post had to be perfect, and if it wasn&#39;t, I was scared to publish it.</p>

<p>The idea of #100DaysToOffload is to let go of this fear and <em>Just. Write.</em> This absolutely worked. I accepted the fact that not every post is perfect and <a href="https://garrit.xyz/posts/2023-04-01-quality-vs.-quantity">sometimes posting more often with worse quality makes way for better posts</a>.</p>

<p>In order to post more often, I also found ways to reduce the friction between me writing a text and publishing it to the blog. I&#39;ve yet to cover this in a post, but I built myself <a href="https://github.com/garritfra/garrit.xyz/blob/main/.github/workflows/publish_via_issue.yaml">a handy script</a> that turns the contents of a GitHub issue into a pull request, ready to be merged as a blog post. This enables me to write posts everywhere I want (like the one right now, which is written on my phone), instead of having to open my laptop, create a new file, write the post and commit it to the repository.</p>

<h2>What&#39;s next?</h2>

<p>I will continue posting when I feel like it! I set myself the goal to publish at least 50 posts a year, but that&#39;s just a rough estimate. If I don&#39;t feel like blogging, I won&#39;t force myself to do it.</p>

<p>All in all, I&#39;m very thankful for having taken part in this challenge. I met <a href="https://kevquirk.com/">a</a> <a href="https://joelchrono.xyz/">bunch</a> <a href="https://claytonerrington.com/">of</a> <a href="https://dougbelshaw.com/">like-minded</a> <a href="https://jlelse.blog/">folks</a> that are happy to discuss whatever I&#39;m rambling about, and it&#39;s great to read whatever they are rambling about as well! I&#39;m also thankful for all the nuggets of information I got to share with you, and also with my future self (seriously, you won&#39;t believe how often I&#39;m looking up old posts and being happy that I wrote that down!).</p>

<p>Thanks for reading, until next time!</p>

<hr/>

<p>This is post 100 of <a href="https://100daystooffload.com/">#100DaysToOffload</a>.</p>]]>
            </description>
        </item>
        <item>
            <title>
                10.000 Hours
            </title>
            <guid>
                https://garrit.xyz/posts/2023-12-22-10-000-hours
            </guid>
            <link>
                https://garrit.xyz/posts/2023-12-22-10-000-hours?utm_source=rss
            </link>
            <pubDate>
                Fri, 22 Dec 2023 00:00:00 +0000
            </pubDate>
            <description>
                <![CDATA[<p>In his book <a href="https://en.m.wikipedia.org/wiki/Outliers_(book)">Outliers</a>, Malcolm Gladwell popularized the idea that it takes 10.000 hours of concentrated practice to master a skill.</p>

<p>According to my <a href="https://wakatime.com">WakaTime</a> stats, I spent 2.384 hours writing code in an editor (December 2023). If you&#39;re reading this post in the future, this is my current record:</p>

<p><a href="https://wakatime.com/@811525e7-5cc5-4eef-9e29-3cece3a03847"><img alt="wakatime" src="https://wakatime.com/badge/user/811525e7-5cc5-4eef-9e29-3cece3a03847.svg"/></a></p>

<p>This time is the time actually spent writing code. It doesn&#39;t track the time reading or thinking about it, nor the time spent in editors without the WakaTime plugin. It&#39;s hard to say how much time I spent engulfed in code, but this number is a good indicator as to how far I&#39;ve come in my programming journey.</p>

<p>I believe we should never say that we&#39;ve &quot;mastered&quot; a craft, even after spending 10.000 hours practicing it. There are always so many things to learn, so many novel ideas to catch up with.</p>

<p>So far, each of my 7 years of working as a software developer has advanced me tremendously. I&#39;m curious to see where I am once I reach 10.000 hours of practice.</p>

<hr/>

<p>This is post 099 of <a href="https://100daystooffload.com/">#100DaysToOffload</a>.</p>]]>
            </description>
        </item>
        <item>
            <title>
                Notes on "Immutability Changes Everything"
            </title>
            <guid>
                https://garrit.xyz/posts/2023-12-21-notes-on-immutability
            </guid>
            <link>
                https://garrit.xyz/posts/2023-12-21-notes-on-immutability?utm_source=rss
            </link>
            <pubDate>
                Thu, 21 Dec 2023 00:00:00 +0000
            </pubDate>
            <description>
                <![CDATA[<blockquote><p>Published books are immutable. Accountants don&#39;t use erasers or they go to jail.</p></blockquote>

<p>The paper <a href="https://www.cidrdb.org/cidr2015/Papers/CIDR15_Paper16.pdf">Immutability Changes Everything</a> by Pat Helland talks about the trend towards immutability in data storage thoughout all layers of the stack. From append-only apps (Record changes, then derive the current state), down to how bits are stored on a hard drive (e.g. Copy on Write).</p>

<p>I stumbled upon this paper through the <a href="https://paperswelove.org/">Papers We Love</a> collection. I was specifically looking for a paper that&#39;s short and easy to comprehend, since I don&#39;t have much experience in reading scientific papers. This is absolutely both short and easy to comprehend. If you&#39;re a beginner like me, I can highly recommend this one to you.</p>

<p>Key takeaways:</p>

<ul><li>Immutability enables clean replication</li><li>Change logs (e.g. <a href="https://en.wikipedia.org/wiki/Write-ahead_logging">write-ahead logs</a>) are the source of truth. The database is a cache of a subset of those change logs</li><li>It&#39;s okay to consider violating <a href="https://en.wikipedia.org/wiki/Database_normalization">normalization</a> rules to trade storage cost for read speed</li><li>Modern SSDs minimize wear by storing new versions of data to other blocks instead of mutating the data in place</li><li>The cost of immutability is increased storage</li></ul>

<hr/>

<p>This is post 098 of <a href="https://100daystooffload.com/">#100DaysToOffload</a>.</p>]]>
            </description>
        </item>
        <item>
            <title>
                Optimizing work batch size
            </title>
            <guid>
                https://garrit.xyz/posts/2023-05-19-work-batch-sizing
            </guid>
            <link>
                https://garrit.xyz/posts/2023-05-19-work-batch-sizing?utm_source=rss
            </link>
            <pubDate>
                Fri, 19 May 2023 00:00:00 +0000
            </pubDate>
            <description>
                <![CDATA[<p>I&#39;ve been playing 
<a href="https://en.m.wikipedia.org/wiki/Carcassonne_(board_game)">Carcassonne</a> a lot with my girlfriend recently. It&#39;s a boardgame about building cities, roads and farms, and each completed &quot;project&quot; earns you some amount of points. The twist is that there&#39;s only a limited number of tiles, and once all tiles are used, the game is over unfinished projects are discarded.</p>

<p>The first couple of playthroughs I tried to maximize my score by increasing the number of projects I actively had going. I&#39;d start a new city or road whenever I could, thinking that the multipliers you sometimes get would pay off in the end. Boy was I wrong.</p>

<p>Where I&#39;m from, we have multiple sayings for this approach. &quot;Having too many irons in the fire&quot; or &quot;dancing on too many parties&quot;. I was too busy starting new projects instead of making actual progress.</p>

<p>A far better approach is to finish projects early, earning less points, but with a greater certainty that they will pay off. With every project you start, the likelyhood of the other projects paying off decreases.</p>

<p>Keeping batch sizes small was a key concept of the <a href="https://en.m.wikipedia.org/wiki/Lean_manufacturing">lean manufacturing movement</a> in the 1980s, and has since been adopted by the <a href="https://de.m.wikipedia.org/wiki/DevOps">DevOps movement</a> for the IT industry. If you want to learn more about this topic, you should check out <a href="https://itrevolution.com/product/the-devops-handbook-second-edition/">The DevOps Handbook</a>. It goes well beyond the basics of making IT processes more productive and efficient.</p>

<p>After realizing that small batch sizes are the key to success, I haven&#39;t lost a game of Carcassonne since. I hope you&#39;re not reading this, honey.🤭</p>

<hr/>

<p>This is post 068 of <a href="https://100daystooffload.com/">#100DaysToOffload</a>.</p>]]>
            </description>
        </item>
        <item>
            <title>
                Serverless Framework Retrospective
            </title>
            <guid>
                https://garrit.xyz/posts/2023-04-28-serverless-framework-retrospective
            </guid>
            <link>
                https://garrit.xyz/posts/2023-04-28-serverless-framework-retrospective?utm_source=rss
            </link>
            <pubDate>
                Fri, 28 Apr 2023 00:00:00 +0000
            </pubDate>
            <description>
                <![CDATA[<p>A current project requires the infrastructure to be highly scalable. It&#39;s expected that &gt; 50k Users hit the platform within a five minute period. Regular ECS containers take about one minute to scale up. That just won&#39;t cut it. I decided to go all in on the <a href="https://www.serverless.com/">serverless</a> framework on AWS. Here&#39;s how it went.</p>

<h3>Setup</h3>

<p>Setting up a serverless application was a breeze. You create a config file and use their CLI to deploy the app.</p>

<h3>The rest of the infrastructure</h3>

<p>I decided to define the rest of the infrastructure (VPC, DB, cache, ...) in Terraform. But, since I wasn&#39;t familiar with how the Serverless Framework worked, I struggled to draw the line between what serverless should handle vs. what the rest of the infrastructure (Terraform) should provide. In a more traditional deployment workflow, you might let the CI deploy a container image to ECR and point the ECS service to that new image.</p>

<p>I chose to let Serverless deploy the entire app through CI and build the rest of the infrastructure around it. The problem with this approach is that we lose fine-grained control over what&#39;s deployed where, which leads to a lot of permission errors.</p>

<p>In retrospect, I should&#39;ve probably chosen the location of the S3 archive as the deployment target for the CI, and then point the lambda function to the location of the new artifact. This defeats the purpose of the framework, but it gives you a lot more control over your infrastructure. Once the next project comes along, I&#39;ll probably go that route instead.</p>

<h3>Permissions</h3>

<p>Serverless suggests to use admin permissions for deployments, and I see where they&#39;re coming from. Managing permissions in this framework is an absolute mess. Here&#39;s what the average deployment workflow looks like, if you want to use fine grained permissions:</p>

<ol><li>Wait for CloudFormation to roll back changes (~2 minutes)</li><li>Update IAM role</li><li>Deploy Serverless App</li><li>If there&#39;s an error, go to 1</li></ol>

<p>Thankfully, some people have already gone through the process of figuring this out. <a href="https://serverlessfirst.com/create-iam-deployer-roles-serverless-app/#determining-deploy-time-permissions">Here&#39;s</a> a great guide with a starting point of the needed permissions.</p>

<h3>Conclusion</h3>

<p>Using the serverless framework is a solid choice if you just want to throw an app out there. Unfortunately the app I was deploying isn&#39;t &quot;just&quot; a dynamic website. The next time I&#39;m building a serverless application it&#39;s probably not going to be with the Serverless Framework, though I learned a lot about serverless applications in general.</p>

<hr/>

<p>This is post 067 of <a href="https://100daystooffload.com/">#100DaysToOffload</a>.</p>]]>
            </description>
        </item>
        <item>
            <title>
                Instant dark theme
            </title>
            <guid>
                https://garrit.xyz/posts/2023-04-12-instant-dark-theme
            </guid>
            <link>
                https://garrit.xyz/posts/2023-04-12-instant-dark-theme?utm_source=rss
            </link>
            <pubDate>
                Wed, 12 Apr 2023 00:00:00 +0000
            </pubDate>
            <description>
                <![CDATA[<p>Thanks to <a href="https://jacksonchen666.com/">Jacksons</a> <a href="https://github.com/garritfra/darktheme.club/pull/79">update to darktheme.club</a>, I just came across a neat little <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/color-scheme">CSS property</a> that turns a mostly CSS-free document into a pleasantly dark site:</p>

<p><code>css
:root {
  color-scheme: light dark;
}
</code></p>

<p>This will adjust all elements on the page to the color scheme preferred by the user - without any other custom styles! 🤯 It is also <a href="https://caniuse.com/mdn-css_properties_color-scheme">widely supported</a> by browsers.</p>

<p>I&#39;ve always been quite dependent on CSS-frameworks for any project I&#39;m starting. Going forward, I&#39;d be interested to see how framework-less sites would feel using this property. If all else fails, there&#39;s always the awesome <a href="https://simplecss.org/">simple.css</a> library, which you can slap on top of a raw document to make it pretty (and dark, if preferred) without using custom classes.</p>

<hr/>

<p>This is post 064 of <a href="https://100daystooffload.com/">#100DaysToOffload</a>.</p>]]>
            </description>
        </item>
        <item>
            <title>
                Designing resilient cloud infrastructure
            </title>
            <guid>
                https://garrit.xyz/posts/2023-03-30-designing-resilient-cloud-infrastructure
            </guid>
            <link>
                https://garrit.xyz/posts/2023-03-30-designing-resilient-cloud-infrastructure?utm_source=rss
            </link>
            <pubDate>
                Thu, 30 Mar 2023 00:00:00 +0000
            </pubDate>
            <description>
                <![CDATA[<p>As mentioned in a <a href="/posts/2023-03-16-terraform-project-learnings">previous post</a>, I&#39;m currently finishing up building my first cloud infrastructure on AWS for a client at work. During the development, I learned a lot about designing components to be resilient and scalable. Here are some key takeaways.</p>

<p>One of the most critical components of a resilient infrastructure is redundancy. On AWS, you place your components inside a &quot;region&quot;. This could be <code>eu-central-1</code> (Frankfurt) or <code>us-east-1</code> (North Virgina), etc. To further reduce the risk of an outage, each region is divided into multiple <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.RegionsAndAvailabilityZones.html">Availability Zones</a> (AZs). The AZs of a region are usually located some distance apart from each other. In case of a flood, a fire or a bomb detonating near one AZ, the other AZs should in most cases still be intact. You should have at least two, preferably three replicas of each component across multiple availability zones in a region. By having replicas of your components in different availability zones, you reduce the risk of downtime caused by an outage in a single availability zone.</p>

<p>Another way to ensure scalability and resilience for your database is to use <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-serverless-v2.html">Aurora Serverless v2</a>. This database service is specifically designed for scalable, on-demand, and cost-effective performance. The database scales itself up or down based on the workload, which allows you to automatically and dynamically adjust the database capacity to meet the demand of your application, ensuring that your application is responsive and performs well without the need for manual intervention. Adding Serverless instances to an existing RDS cluster is also a seemless proccess.</p>

<p>In addition to switching to Aurora Serverless v2, using read replicas for cache and database in a separate availability zone can act as a hot standby without extra configuration. Keep in mind that read replicas are only utilized by explicitly using the read-only endpoint of a cluster. But even if you&#39;re only using the &quot;main&quot; cluster endpoint (and therefore just the primary instance), a read replica can promote itself to the primary instance in case of a fail over, which drastically reduces downtime.</p>

<p>When using Amazon Elastic Container Service (ECS), use Fargate as opposed to EC2 instances. Fargate is a serverless compute engine for containers that allows you to run containers without having to manage the underlying infrastructure. It smartly locates instances across availability zones, ensuring that your application is always available.</p>

<p>In conclusion, you should always ensure that there are more than one instance of a component in your infrastructure. There are also services on AWS that abstract away the physical infrastructure (Fargate, S3, Lambda) and use a multi-AZ pattern by default.</p>

<hr/>

<p>This is post 061 of <a href="https://100daystooffload.com/">#100DaysToOffload</a>.</p>]]>
            </description>
        </item>
        <item>
            <title>
                Terraform project learnings
            </title>
            <guid>
                https://garrit.xyz/posts/2023-03-16-terraform-project-learnings
            </guid>
            <link>
                https://garrit.xyz/posts/2023-03-16-terraform-project-learnings?utm_source=rss
            </link>
            <pubDate>
                Thu, 16 Mar 2023 00:00:00 +0000
            </pubDate>
            <description>
                <![CDATA[<p>I just finished my first ever infrastructure project for a client. My Terraform skills are good enough to be dangerous, but during the development of this project I learned a lot that I would do differently next time.</p>

<h2>Project structure</h2>

<p>Having worked with semi-professional Terraform code before, I applied what I knew to my new project. That was mainly that we have a shared base and an overlay directory for each environment. I went with a single Terraform module for the shared infrastructure, and variables for each environment. Naively, roughly every service had their own file.</p>

<p><code>
.
├── modules
│   └── infrastructure
│       ├── alb.tf
│       ├── cache.tf
│       ├── database.tf
│       ├── dns.tf
│       ├── ecr.tf
│       ├── ecs.tf
│       ├── iam.tf
│       ├── logs.tf
│       ├── main.tf
│       ├── network.tf
│       ├── secrets.tf
│       ├── security.tf
│       ├── ssl.tf
│       ├── state.tf
│       └── variables.tf
├── production
│   ├── main.tf
│   └── secrets.tf
└── staging
    ├── main.tf
    └── secrets.tf
</code></p>

<p>This works very well, but I already started running into issues extending this setup. For my next project, I would probably find individual components and turn them into smaller reusable submodules. If I were to rewrite the project above, I would probably structure it like this (not a complete project, but I think you get the idea):</p>

<p><code>
.
├── modules
│   └── infrastructure
│       ├── main.tf
│       ├── modules
│       │   ├── database
│       │   │   ├── iam.tf
│       │   │   ├── logs.tf
│       │   │   ├── main.tf
│       │   │   ├── outputs.tf
│       │   │   ├── rds.tf
│       │   │   └── variables.tf
│       │   ├── loadbalancer
│       │   │   ├── alb.tf
│       │   │   ├── logs.tf
│       │   │   ├── main.tf
│       │   │   ├── outputs.tf
│       │   │   └── variables.tf
│       │   ├── network
│       │   │   ├── dns.tf
│       │   │   ├── logs.tf
│       │   │   ├── main.tf
│       │   │   ├── outputs.tf
│       │   │   ├── ssl.tf
│       │   │   ├── variables.tf
│       │   │   └── vpc.tf
│       │   ├── service
│       │   │   ├── ecr.tf
│       │   │   ├── ecs.tf
│       │   │   ├── iam.tf
│       │   │   ├── logs.tf
│       │   │   ├── main.tf
│       │   │   ├── outputs.tf
│       │   │   └── variables.tf
│       │   └── state
│       │       ├── locks.tf
│       │       ├── main.tf
│       │       ├── outputs.tf
│       │       ├── s3.tf
│       │       └── variables.tf
│       ├── main.tf
│       ├── outputs.tf
│       └── variables.tf
├── production
│   ├── main.tf
│   └── secrets.tf
└── staging
    ├── main.tf
    └── secrets.tf
</code></p>

<h2>Secrets</h2>

<p>I decided to use <a href="https://github.com/AGWA/git-crypt">git-crypt</a> to manage secrets, but that was only before I learned about <a href="https://github.com/mozilla/sops">SOPS</a>. It&#39;s too late to migrate now, but if I could, I would choose SOPS for secrets any day of the week for upcoming projects. It even has a <a href="https://registry.terraform.io/providers/carlpett/sops/latest/docs">Terraform provider</a>, so there&#39;s no excuse not to use it. ;)</p>

<h2>Conclusion</h2>

<p>Overall I&#39;m pretty happy with how the project turned out, but there are some things that I learned during this project that will pay off later.</p>

<hr/>

<p>This is post 057 of <a href="https://100daystooffload.com/">#100DaysToOffload</a>.</p>]]>
            </description>
        </item>
    </channel>
</rss>